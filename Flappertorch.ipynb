{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorbuenog/Flapper/blob/main/Flappertorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import numpy\n",
        "import scipy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.path as mpath\n",
        "from matplotlib.markers import MarkerStyle\n",
        "import matplotlib.font_manager as fm\n",
        "plt.ioff()\n",
        "\n",
        "import gym\n",
        "from gym import wrappers\n",
        "from gym import spaces\n",
        "\n",
        "import imageio"
      ],
      "metadata": {
        "id": "V1tlyuUFgqtI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QuAwnp9LVMnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605ac78d-a7a1-44a0-bcae-42f78573605e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "class InitialCondition(object):\n",
        "\n",
        "    def __init__(self, distance=None, f2=None, A2=None, goal=None):\n",
        "        self.distance = distance if distance is not None else 21.5\n",
        "        self.A1 = 2.0\n",
        "        self.f1 = 1.0\n",
        "        self.A2 = 2.0 if A2 is None else A2\n",
        "        self.f2 = 1.0 if f2 is None else f2\n",
        "        self.goal = goal if goal is not None else 21.5\n",
        "\n",
        "        self.u2 = numpy.pi * self.A2 * self.f2 * numpy.sqrt(2 * SwimmerEnv.Ct / SwimmerEnv.Cd)\n",
        "        self.v2 = -self.A2*(2 * numpy.pi * self.f2)\n",
        "        self.v_flow = self.A1*self.f1*numpy.cos(2*numpy.pi*self.f1*(-SwimmerEnv.dt))*numpy.exp(-SwimmerEnv.dt/SwimmerEnv.T)\n",
        "        self.flow_agreement = self.v2 * self.v_flow\n",
        "\n",
        "    def random(self, randomize_fields=[]):\n",
        "        if 'distance' in randomize_fields:\n",
        "            self.distance = random.uniform(10,30)\n",
        "        if 'f2' in randomize_fields:\n",
        "            self.f2 = random.uniform(0.5, 1.5)\n",
        "        if 'A2' in randomize_fields:\n",
        "            self.A2 = random.uniform(.5, 3.0)\n",
        "        if 'v2' in randomize_fields:\n",
        "            self.v2 = random.uniform(-1.0, 1.0)\n",
        "        return self\n",
        "\n",
        "\n",
        "class SwimmerEnv(gym.Env):\n",
        "\n",
        "    s = 15.\n",
        "    c = 4.\n",
        "    As = s * c\n",
        "    T = .5\n",
        "    m = 80.\n",
        "    Ct = .96\n",
        "    Cd = .25\n",
        "    rho = 1.\n",
        "    dt = 0.1\n",
        "\n",
        "    def __init__(self, action=None, observations=[], rewards=[]):\n",
        "        super(SwimmerEnv, self).__init__()\n",
        "\n",
        "        self.action_space = spaces.Discrete(3) # discrete action as 0, 1, or 2\n",
        "        self.action = action  # None, 'f2', or 'A2'\n",
        "\n",
        "        obs_low, obs_high = [], []\n",
        "        if 'distance' in observations:\n",
        "            obs_low.append(-numpy.inf)\n",
        "            obs_high.append(numpy.inf)\n",
        "        if 'f2' in observations:\n",
        "            obs_low.append(0.)\n",
        "            obs_high.append(10.)\n",
        "        if 'A2' in observations:\n",
        "            obs_low.append(0.5)\n",
        "            obs_high.append(3.0)\n",
        "        if 'flow agreement' in observations:\n",
        "            obs_low.append(-numpy.inf)\n",
        "            obs_high.append(numpy.inf)\n",
        "        if 'avg flow agreement' in observations:\n",
        "            obs_low.append(-numpy.inf)\n",
        "            obs_high.append(numpy.inf)\n",
        "        if 'velocity' in observations:\n",
        "            obs_low.append(0.)\n",
        "            obs_high.append(numpy.inf)\n",
        "\n",
        "        self.observation_space = spaces.Box(low=numpy.array(obs_low), high=numpy.array(obs_high), dtype=numpy.float32)\n",
        "        self.observations = observations\n",
        "\n",
        "        self.rewards = rewards\n",
        "\n",
        "        self.flap = None\n",
        "        self.t_bound = 500.\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def _shoot(self, A1, A2, f1, f2, vec_initial, t_start=0., t_bound=5000., method='RK45'):\n",
        "        rho = self.rho\n",
        "        As = self.As\n",
        "        T = self.T\n",
        "        m = self.m\n",
        "        Ct = self.Ct\n",
        "        Cd = self.Cd\n",
        "        c = self.c\n",
        "\n",
        "        def fun(t, vec):\n",
        "            x2, u2 = vec\n",
        "            u1 = numpy.pi * A1 * f1 * numpy.sqrt(2 * Ct / Cd)  # Leader velocity (constant)\n",
        "            dt = -x2 / u1 + t\n",
        "            Ft2 = 2*rho*As*Ct*numpy.pi**2*((A2*f2*numpy.cos(2*numpy.pi*f2*t)-A1*f1*numpy.cos(2*numpy.pi*f1*(t-dt))*numpy.exp(-dt/T)))**2\n",
        "            dy_dt = (u2, (Ft2 - rho*As*Cd*u2**2/2)/m)\n",
        "            return numpy.asarray(dy_dt)\n",
        "        # events = [lambda t, y: y[0] - y[4] - 0.00001]\n",
        "        events = []\n",
        "        for ee in events: setattr(ee, 'terminal', True)\n",
        "        solver = scipy.integrate.solve_ivp(fun, (t_start, t_bound), vec_initial, method=method, events=events,\n",
        "                                            rtol=1e-4, atol=1e-7, max_step=.03, first_step=.001, dense_output=True)\n",
        "        u1 = numpy.pi * A1 * f1 * numpy.sqrt(2 * Ct / Cd)  # Leader velocity (constant)\n",
        "        x1 = u1 * solver.t[-1]  # Leader x-coord (calculated)\n",
        "        y1 = A1 * numpy.sin(2 * numpy.pi * f1 * solver.t[-1])  # Leader y-coord (calculated)\n",
        "        v1 = -A1*(2 * numpy.pi * f1)*numpy.cos(2 * numpy.pi * f1 * solver.t[-1])\n",
        "        y2 = A2 * numpy.sin(2 * numpy.pi * f2 * solver.t[-1])  # Leader y-coord (calculated)\n",
        "        v2 = -A2*(2 * numpy.pi * f2)*numpy.cos(2 * numpy.pi * f2 * solver.t[-1])\n",
        "        values = list(zip(solver.t, solver.y.T))\n",
        "\n",
        "        info = {\n",
        "            'x1': x1,\n",
        "            'y1': y1,\n",
        "            'u1': u1,\n",
        "            'v1': v1,\n",
        "            'x2': values[-1][1][0],\n",
        "            'y2': y2,\n",
        "            'u2': values[-1][1][1],\n",
        "            'v2': v2,\n",
        "        }\n",
        "        return solver, values, info\n",
        "\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = []\n",
        "        if 'distance' in self.observations:\n",
        "            obs.append(self.distance)\n",
        "        if 'f2' in self.observations:\n",
        "            obs.append(self.f2)\n",
        "        if 'A2' in self.observations:\n",
        "            obs.append(self.A2)\n",
        "        if 'flow agreement' in self.observations:\n",
        "            obs.append(self.flow_agreement)\n",
        "        if 'avg flow agreement' in self.observations:\n",
        "            obs.append(self.avg_flow_agreement)\n",
        "        if 'velocity' in self.observations:\n",
        "            obs.append(self.u2)\n",
        "        obs = numpy.array(obs, dtype=numpy.float32)\n",
        "        return obs\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        Ct = self.Ct\n",
        "        Cd = self.Cd\n",
        "\n",
        "        increment = (action - 1) * .1\n",
        "        if self.action == 'f2':\n",
        "            self.f2 = self.f2 + increment\n",
        "        elif self.action == 'A2':\n",
        "            self.A2 = self.A2 + increment\n",
        "\n",
        "        t_bound_step = self.dt\n",
        "        solver, values, shoot_info = self._shoot(self.A1, self.A2, self.f1, self.f2, self.flap, t_start=self.tt, t_bound=self.tt+t_bound_step)\n",
        "        self.flap = values[-1][1]\n",
        "        self.tt += self.dt\n",
        "        self.u1 = numpy.pi * self.A1 * self.f1 * numpy.sqrt(2 * Ct / Cd)  # Leader velocity\n",
        "        self.x1 = self.u1 * self.tt  # Leader x-coord\n",
        "        self.y1 = self.A1 * numpy.sin(2 * numpy.pi * self.f1 * self.tt)  # Leader y-coord\n",
        "        self.y2 = self.A2 * numpy.sin(2 * numpy.pi * self.f2 * self.tt)  # Follower y-coord\n",
        "        self.v1 = -self.A1*(2 * numpy.pi * self.f1)*numpy.cos(2 * numpy.pi * self.f1 * self.tt)\n",
        "        self.t_delay = self.tt - self.flap[0]/self.u1\n",
        "        v_flow = self.A1*self.f1*numpy.cos(2*numpy.pi*self.f1*(self.tt-self.t_delay))*numpy.exp(-self.t_delay/self.T)\n",
        "        self.t_delay_head = self.tt - (self.flap[0]+self.c)/self.u1\n",
        "        v_flow_head = self.A1*self.f1*numpy.cos(2*numpy.pi*self.f1*(self.tt-self.t_delay_head))*numpy.exp(-self.t_delay_head/self.T)\n",
        "        v_gradient = (v_flow_head - v_flow)/self.c\n",
        "\n",
        "        self.distance = self.x1 - self.flap[0]-self.c  # Distance between leader and follower\n",
        "        done = False\n",
        "        new_distance_from_goal = numpy.abs(self.distance - self.goal) # Distance\n",
        "        new_flow_agreement = shoot_info['v2'] * v_flow_head # Flow agreement\n",
        "        a_flow = (v_flow-self.previous_v_flow)/self.dt # Flow acceleration\n",
        "        self.u2 = self.flap[1]\n",
        "\n",
        "        # Calculate average flow agreement over one period\n",
        "        self.flow_agreement_history.append(new_flow_agreement)\n",
        "        if len(self.flow_agreement_history) > 10:\n",
        "            self.flow_agreement_history.pop(0)\n",
        "        new_avg_flow_agreement = numpy.mean(self.flow_agreement_history)\n",
        "\n",
        "        # Calculate average follower velocity over one period\n",
        "        self.u2_history.append(self.u2)\n",
        "        if len(self.u2_history) > 10:\n",
        "            self.u2_history.pop(0)\n",
        "        self.avg_u2 = numpy.mean(self.u2_history)\n",
        "\n",
        "        # Reset reward\n",
        "        self.reward = 0.\n",
        "\n",
        "        if 'distance' in self.rewards:\n",
        "            self.reward += (self.distance_from_goal - new_distance_from_goal)\n",
        "\n",
        "        if 'flow agreement' in self.rewards:\n",
        "            self.reward += (new_flow_agreement - self.flow_agreement)\n",
        "\n",
        "        if 'flow acceleration' in self.rewards:\n",
        "            self.reward += a_flow\n",
        "\n",
        "        if 'velocity' in self.rewards:\n",
        "            self.reward = -numpy.abs(self.avg_u2 - self.u1)\n",
        "\n",
        "        if 'avg flow agreement' in self.rewards:\n",
        "            self.reward += new_avg_flow_agreement\n",
        "\n",
        "        self.previous_v_flow = v_flow\n",
        "        self.distance_from_goal = new_distance_from_goal\n",
        "        self.flow_agreement = new_flow_agreement\n",
        "        self.avg_flow_agreement = new_avg_flow_agreement\n",
        "        self.last_reward = self.reward\n",
        "\n",
        "        # Penalize extreme behaviors\n",
        "        if self.distance < 0.:\n",
        "            self.reward -= 100\n",
        "            done = True\n",
        "        elif self.distance > 200:\n",
        "            self.reward -= 100\n",
        "            done = True\n",
        "\n",
        "        info = {\n",
        "            'distance': self.distance,\n",
        "            'action': action,\n",
        "            'reward': self.reward,\n",
        "            'done': done,\n",
        "            'freq1': self.f1,\n",
        "            'freq2': self.f2,\n",
        "            'distance_from_goal': self.distance_from_goal,\n",
        "            't': self.tt,\n",
        "            'v_flow': v_flow,\n",
        "            'v_flow_head': v_flow_head,\n",
        "            'a_flow': a_flow,\n",
        "            'flow_agreement': new_flow_agreement,\n",
        "            'avg_flow_agreement': new_avg_flow_agreement,\n",
        "            'u2': self.flap[1],\n",
        "            'avg_u2': self.avg_u2,\n",
        "            'v_gradient': v_gradient,\n",
        "        }\n",
        "        info.update(shoot_info)\n",
        "\n",
        "        return self._get_obs(), self.reward, done, info\n",
        "\n",
        "    def reset(self, initial_condition=None, initial_condition_fn=None):\n",
        "        Ct = self.Ct\n",
        "        Cd = self.Cd\n",
        "        gap_distance_in_wavelengths = 1.\n",
        "\n",
        "        # get initial condition\n",
        "        if initial_condition is None:\n",
        "            if initial_condition_fn is not None:\n",
        "                initial_condition = initial_condition_fn()\n",
        "            else:\n",
        "                initial_condition = InitialCondition()\n",
        "\n",
        "        self.A1 = initial_condition.A1\n",
        "        self.f1 = initial_condition.f1\n",
        "        self.A2 = initial_condition.A2\n",
        "        self.f2 = initial_condition.f2\n",
        "        self.goal = initial_condition.goal\n",
        "\n",
        "        u2_initial = initial_condition.u2\n",
        "\n",
        "        self.distance = initial_condition.distance\n",
        "        self.distance_from_goal = numpy.abs(self.distance - self.goal)\n",
        "        self.flow_agreement = initial_condition.flow_agreement\n",
        "        self.flap = numpy.asarray([-initial_condition.distance, u2_initial])\n",
        "        self.tt = 0\n",
        "        self.previous_v_flow = 0\n",
        "        self.flow_agreement_history = []\n",
        "        self.u2_history = []\n",
        "        self.previous_x2 = -initial_condition.distance\n",
        "        self.flow_agreement = initial_condition.flow_agreement\n",
        "        self.avg_flow_agreement = 0\n",
        "        self.u2 = .1\n",
        "\n",
        "        return self._get_obs()\n",
        "\n",
        "    def render(self, mode='rgb_array'):\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(self.x1, self.y1, label='leader')\n",
        "        ax.scatter([self.flap[0]], [self.flap[1]], label='follower')\n",
        "        ax.set_xlim([self.x1 - 50, self.x1 + 5])\n",
        "        ax.set_ylim([-2*self.A1, 2*self.A1])\n",
        "        ax.legend()\n",
        "        fig.canvas.draw()\n",
        "        fig.canvas.tostring_rgb()\n",
        "        frame = numpy.frombuffer(fig.canvas.tostring_rgb(), dtype=numpy.uint8)\n",
        "        frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "        plt.close(fig)\n",
        "        return frame\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "Kp-2bJ7mSifa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Memory(object):\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.is_terminals = []\n",
        "\n",
        "    def clear_memory(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.is_terminals[:]\n",
        "\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, n_latent_var):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.affine = nn.Linear(state_dim, n_latent_var)\n",
        "\n",
        "        # actor\n",
        "        self.action_layer = nn.Sequential(\n",
        "                nn.Linear(state_dim, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, action_dim),\n",
        "                nn.Softmax(dim=-1)\n",
        "                )\n",
        "\n",
        "        # critic\n",
        "        self.value_layer = nn.Sequential(\n",
        "                nn.Linear(state_dim, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, n_latent_var),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(n_latent_var, 1)\n",
        "                )\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def act(self, state, memory):\n",
        "        state = torch.from_numpy(state).float().to(device)\n",
        "        action_probs = self.action_layer(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        action = dist.sample()\n",
        "\n",
        "        memory.states.append(state)\n",
        "        memory.actions.append(action)\n",
        "        memory.logprobs.append(dist.log_prob(action))\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def evaluate(self, state, action):\n",
        "        action_probs = self.action_layer(state)\n",
        "        dist = Categorical(action_probs)\n",
        "\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "\n",
        "        state_value = self.value_layer(state)\n",
        "\n",
        "        return action_logprobs, torch.squeeze(state_value), dist_entropy\n",
        "\n",
        "class PPO(object):\n",
        "    def __init__(self, state_dim, action_dim, n_latent_var, lr, betas, gamma, K_epochs, eps_clip):\n",
        "        self.lr = lr\n",
        "        self.betas = betas\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "\n",
        "        self.policy = ActorCritic(state_dim, action_dim, n_latent_var).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr=lr, betas=betas)\n",
        "        self.policy_old = ActorCritic(state_dim, action_dim, n_latent_var).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "    def update(self, memory):\n",
        "        # Monte Carlo estimate of state rewards:\n",
        "        rewards = []\n",
        "        discounted_reward = 0\n",
        "        for reward, is_terminal in zip(reversed(memory.rewards), reversed(memory.is_terminals)):\n",
        "            if is_terminal:\n",
        "                discounted_reward = 0\n",
        "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "            rewards.insert(0, discounted_reward)\n",
        "\n",
        "        # Normalizing the rewards:\n",
        "        rewards = torch.tensor(rewards).to(device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-5)\n",
        "        rewards = rewards.type(torch.float32)\n",
        "\n",
        "        # convert list to tensor\n",
        "        old_states = torch.stack(memory.states).to(device).detach()\n",
        "        old_actions = torch.stack(memory.actions).to(device).detach()\n",
        "        old_logprobs = torch.stack(memory.logprobs).to(device).detach()\n",
        "\n",
        "        # Optimize policy for K epochs:\n",
        "        for _ in range(self.K_epochs):\n",
        "            # Evaluating old actions and values :\n",
        "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "            # Ensure state_values are float32\n",
        "            state_values = state_values.type(torch.float32)\n",
        "\n",
        "            # Finding the ratio (pi_theta / pi_theta__old):\n",
        "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "            # Finding Surrogate Loss:\n",
        "            advantages = rewards - state_values.detach()\n",
        "            surr1 = ratios * advantages\n",
        "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
        "\n",
        "            # take gradient step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Copy new weights into old policy:\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self, **env_args):\n",
        "        ############## Hyperparameters ##############\n",
        "        self.env_name = \"Flappers\"\n",
        "        self.env = SwimmerEnv(**env_args)\n",
        "        self.state_dim = self.env.observation_space.shape[0]\n",
        "        self.action_dim = 3\n",
        "        self.render = False\n",
        "        self.solved_reward = 500         # stop training if avg_reward > solved_reward\n",
        "        self.log_interval = 20           # print avg reward in the interval\n",
        "        self.max_episodes = 1000        # max training episodes\n",
        "        self.max_timesteps = 500       # max timesteps in one episode\n",
        "        self.n_latent_var = 64           # number of variables in hidden layer\n",
        "        self.update_timestep = 200    # update policy every n timesteps\n",
        "        self.lr = 0.002\n",
        "        self.betas = (0.9, 0.999)\n",
        "        self.gamma = 0.99                # discount factor\n",
        "        self.K_epochs = 4               # update policy for K epochs\n",
        "        self.eps_clip = 0.2              # clip parameter for PPO\n",
        "        self.random_seed = 4\n",
        "        #############################################\n",
        "\n",
        "        if self.random_seed:\n",
        "            torch.manual_seed(self.random_seed)\n",
        "            self.env.seed(self.random_seed)\n",
        "\n",
        "        self.memory = Memory()\n",
        "        self.ppo = PPO(self.state_dim, self.action_dim, self.n_latent_var, self.lr, self.betas, self.gamma, self.K_epochs, self.eps_clip)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        self.ppo.policy.load_state_dict(torch.load(model_path))\n",
        "        self.ppo.policy_old.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    def get_policy(self, episodes=1000):\n",
        "        pol_name = f\"PPO_{self.env_name}_{episodes}_ACT_{self.env.action}_OBS_{self.env.observations}_REW_{self.env.rewards}.pth\"\n",
        "        return pol_name\n",
        "\n",
        "    def train(self, initial_condition=None, initial_condition_fn=None, episodes=None):\n",
        "\n",
        "        # logging variables\n",
        "        running_reward = 0\n",
        "        avg_length = 0\n",
        "        timestep = 0\n",
        "        history = []\n",
        "\n",
        "        # header\n",
        "        with open(f\"log_PPO_{self.env_name}_ACT_{self.env.action}_OBS_{self.env.observations}_REW_{self.env.rewards}.csv\", 'a') as f:\n",
        "                    f.write(f'Episode,avg length,reward\\n')\n",
        "        # training loop\n",
        "        if episodes is None:\n",
        "            episodes = self.max_episodes\n",
        "        for i_episode in range(1, episodes+1):\n",
        "            state = self.env.reset(initial_condition=initial_condition, initial_condition_fn=initial_condition_fn)\n",
        "            for t in range(self.max_timesteps):\n",
        "                timestep += 1\n",
        "\n",
        "                # Running policy_old:\n",
        "                action = self.ppo.policy_old.act(state, self.memory)\n",
        "                state, reward, done, info = self.env.step(action)\n",
        "\n",
        "                # Saving reward and is_terminal:\n",
        "                self.memory.rewards.append(reward)\n",
        "                self.memory.is_terminals.append(done)\n",
        "\n",
        "                # update if its time\n",
        "                if timestep % self.update_timestep == 0:\n",
        "                    self.ppo.update(self.memory)\n",
        "                    self.memory.clear_memory()\n",
        "                    timestep = 0\n",
        "\n",
        "                running_reward += reward\n",
        "                if self.render:\n",
        "                    self.env.render()\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "                history.append(info)\n",
        "\n",
        "            avg_length += t\n",
        "\n",
        "            filename = f\"./PPO_{self.env_name}_{i_episode}_ACT_{self.env.action}_OBS_{self.env.observations}_REW_{self.env.rewards}.pth\"\n",
        "            # stop training if avg_reward > solved_reward\n",
        "            # if running_reward > (self.log_interval*self.solved_reward):\n",
        "            #     print(\"########## Solved! ##########\")\n",
        "            #     torch.save(self.ppo.policy.state_dict(), filename)\n",
        "            #     break\n",
        "            # save every 1000 episodes\n",
        "            if i_episode % 1000 == 0:\n",
        "                    torch.save(self.ppo.policy.state_dict(), filename)\n",
        "            # logging\n",
        "            if i_episode % self.log_interval == 0:\n",
        "                avg_length = int(avg_length/self.log_interval)\n",
        "                running_reward = ((running_reward/self.log_interval))\n",
        "\n",
        "                print('Episode {} \\t avg length: {} \\t reward: {}'.format(i_episode, avg_length, running_reward))\n",
        "\n",
        "                # Save message on csv file\n",
        "                with open(f\"log_PPO_{self.env_name}_ACT_{self.env.action}_OBS_{self.env.observations}_REW_{self.env.rewards}.csv\", 'a') as f:\n",
        "                    f.write(f'{i_episode},{avg_length},{running_reward}\\n')\n",
        "                running_reward = 0\n",
        "                avg_length = 0\n",
        "\n",
        "        return history;\n",
        "\n",
        "    def plot_policy(self, fa_range=None, f2_range=None, a2_range=None, d_range=None, u_range=None):\n",
        "            action_choices = []\n",
        "\n",
        "            if len(self.env.observations) == 0:\n",
        "                raise ValueError(\"No observations provided\")\n",
        "            elif len(self.env.observations) == 1:\n",
        "                pair = (self.env.observations[0], self.env.observations[0])\n",
        "            elif len(self.env.observations) == 2:\n",
        "                pair = (self.env.observations[0], self.env.observations[1])\n",
        "            else:\n",
        "                raise ValueError(\"Too many observations provided\")\n",
        "\n",
        "            ranges = {\n",
        "                'flow agreement': fa_range,\n",
        "                'distance': d_range,\n",
        "                'f2': f2_range,\n",
        "                'A2': a2_range,\n",
        "                'velocity': u_range\n",
        "            }\n",
        "            range1 = ranges[pair[0]]\n",
        "            range2 = ranges[pair[1]]\n",
        "\n",
        "            for x1 in range1:\n",
        "                for x2 in range2:\n",
        "                    state = numpy.array([x1, x2], dtype=numpy.float32)\n",
        "                    state_tensor = torch.from_numpy(state).float().to(device)\n",
        "                    with torch.no_grad():\n",
        "                        action_probs = self.ppo.policy.action_layer(state_tensor).cpu().numpy()\n",
        "                    action = numpy.argmax(action_probs)\n",
        "                    action_choices.append((x1, x2, action))\n",
        "\n",
        "            action_choices = numpy.array(action_choices)\n",
        "            print(action_choices.shape)\n",
        "\n",
        "            plt.figure(figsize=(12, 6))\n",
        "\n",
        "            scatter = plt.scatter(action_choices[:, 0], action_choices[:, 1], c=action_choices[:, 2], cmap='viridis', marker='o')\n",
        "            handles = [plt.Line2D([], [], color=scatter.cmap(scatter.norm(i)), marker='o', linestyle='', markersize=5, label=label)\n",
        "                      for i, label in enumerate(['Reduce', 'Mantain', 'Increase'])]\n",
        "            plt.legend(handles=handles, title='Chosen Action')\n",
        "            plt.title(f'Chosen Action Based on State ({pair[0]} and {pair[1]})')\n",
        "            plt.xlabel(pair[0])\n",
        "            plt.ylabel(pair[1])\n",
        "            plt.xticks(numpy.linspace(min(range1), max(range1), 11))\n",
        "            plt.yticks(numpy.linspace(min(range2), max(range2), 11))\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "    def test_initial_conditions(self, initial_conditions):\n",
        "\n",
        "        max_timesteps = 500\n",
        "\n",
        "        # plt.figure(figsize=(10, 6))\n",
        "        fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(10, 12))\n",
        "\n",
        "        for ic in initial_conditions:\n",
        "            obs = self.env.reset(initial_condition=ic)\n",
        "            schooling_numbers = []\n",
        "            flow_agreements = []\n",
        "            avg_flow_agreements = []\n",
        "            v_gradients = []\n",
        "            u2 = []\n",
        "            for t in range(max_timesteps):\n",
        "                action = self.ppo.policy.act(obs, Memory())\n",
        "                obs, reward, done, info = self.env.step(action)\n",
        "                schooling_number = (info['distance']-SwimmerEnv.c)/info['u1']/info['freq1']\n",
        "                schooling_numbers.append(schooling_number)\n",
        "                flow_agreements.append(info['flow_agreement'])\n",
        "                avg_flow_agreements.append(info['avg_flow_agreement'])\n",
        "                v_gradients.append(info['v_gradient'])\n",
        "                u2.append(info['avg_u2'])\n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "            # plt.plot(distances, label=f\"Initial Distance: {ic.distance}\")\n",
        "            ax1.plot(schooling_numbers, label=f\"Initial Distance: {ic.distance}\")\n",
        "\n",
        "            ax2.plot(flow_agreements, label=f\"Initial Distance: {ic.distance}\")\n",
        "\n",
        "            ax3.plot(avg_flow_agreements, label=f\"Initial Distance: {ic.distance}\")\n",
        "\n",
        "            ax4.plot(v_gradients, label=f\"Initial Distance: {ic.distance}\")\n",
        "\n",
        "            ax5.plot(u2, label=f\"Initial Distance: {ic.distance}\")\n",
        "\n",
        "        ax1.set_xlabel('Timesteps (0.1 s)')\n",
        "        ax1.set_ylabel('Schooling Number')\n",
        "        ax1.set_title('Distance Between Leader and Follower for Different Initial Conditions')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True)\n",
        "\n",
        "        ax2.set_xlabel('Timesteps (0.1 s)')\n",
        "        ax2.set_ylabel('Flow Agreement')\n",
        "        # ax2.set_xlim([0, 100])\n",
        "        ax2.set_title('Flow Agreement for Different Initial Conditions')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True)\n",
        "\n",
        "        ax3.set_xlabel('Timesteps (0.1 s)')\n",
        "        ax3.set_ylabel('Average Flow Agreement')\n",
        "        # ax3.set_xlim([0, 100])\n",
        "        ax3.set_title('Average Flow Agreement for Different Initial Conditions')\n",
        "        ax3.legend()\n",
        "        ax3.grid(True)\n",
        "\n",
        "        ax4.set_xlabel('Timesteps (0.1 s)')\n",
        "        ax4.set_ylabel('Velocity Gradient')\n",
        "        # ax4.set_xlim([0,100])\n",
        "        std_vel_gradient = numpy.std(v_gradients)\n",
        "        ax4.set_ylim([-3*std_vel_gradient,3*std_vel_gradient])\n",
        "        ax4.set_title('Velocity Gradient for Different Initial Conditions')\n",
        "        ax4.legend()\n",
        "        ax4.grid(True)\n",
        "\n",
        "        ax5.set_xlabel('Timesteps (0.1 s)')\n",
        "        ax5.set_ylabel('Horizontal Velocity')\n",
        "        # ax5.set_xlim([0,100])\n",
        "        ax5.set_title('Average Velocity for Different Initial Conditions')\n",
        "        ax5.legend()\n",
        "        ax5.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def naca_airfoil(self, code, num_points=100):\n",
        "        \"\"\"Generates the coordinates of a NACA 4-digit airfoil.\"\"\"\n",
        "        m = float(code[0]) / 100.0  # Maximum camber\n",
        "        p = float(code[1]) / 10.0  # Location of maximum camber\n",
        "        t = float(code[2:]) / 100.0  # Maximum thickness\n",
        "\n",
        "        x = numpy.linspace(0, 1, num_points)\n",
        "        yt = 5 * t * (0.2969 * numpy.sqrt(x) - 0.1260 * x - 0.3516 * x**2 + 0.2843 * x**3 - 0.1015 * x**4)\n",
        "\n",
        "        if m == 0 and p == 0:\n",
        "            yc = numpy.zeros_like(x)\n",
        "            theta = numpy.zeros_like(x)\n",
        "        else:\n",
        "            yc = numpy.where(x <= p,\n",
        "                            m / p**2 * (2 * p * x - x**2),\n",
        "                            m / (1 - p)**2 * ((1 - 2 * p) + 2 * p * x - x**2))\n",
        "            theta = numpy.arctan(numpy.gradient(yc, x))\n",
        "\n",
        "        xu = x - yt * numpy.sin(theta)\n",
        "        yu = yc + yt * numpy.cos(theta)\n",
        "        xl = x + yt * numpy.sin(theta)\n",
        "        yl = yc - yt * numpy.cos(theta)\n",
        "\n",
        "        # Close the path by adding the first point to the end\n",
        "        x_coords = -numpy.concatenate([xu, xl[::-1]])\n",
        "        y_coords = numpy.concatenate([yu, yl[::-1]])\n",
        "\n",
        "        return mpath.Path(numpy.column_stack([x_coords, y_coords]))\n",
        "\n",
        "    def animate(self, i):\n",
        "        font_prop = fm.FontProperties(size=35)\n",
        "        self.ax.clear()\n",
        "        x_leader = self.leader_positions[i][0]\n",
        "        y_leader = self.leader_positions[i][1]\n",
        "        x_follower = self.follower_positions[i][0]\n",
        "        y_follower = self.follower_positions[i][1]\n",
        "        self.ax.set_xlim([x_leader - 50, x_leader + 5])\n",
        "        self.ax.set_ylim([-1.5 * self.env.A1, 1.5 * self.env.A1])\n",
        "        self.ax.scatter(x_leader, y_leader, label='leader', color='black', marker=self.fish_marker)\n",
        "        self.ax.scatter(x_follower, y_follower, label='follower', color='black', marker=self.fish_marker)\n",
        "        self.ax.grid(True, axis='x', color='grey')\n",
        "        self.ax.set_xlabel('X Position (cm)', fontproperties = font_prop)\n",
        "        self.ax.set_ylabel('Y Position (cm)', fontproperties = font_prop)\n",
        "        self.ax.tick_params(axis='both', which='major', labelsize=30)\n",
        "\n",
        "        # Display wake\n",
        "        for j, wake_pos in enumerate(self.leader_positions[:i]):\n",
        "            alpha = 1.0 - (i-j) / len(self.leader_positions)\n",
        "            wake = self.v_flow_history[j]\n",
        "            marker_size = 5 + 5*abs(wake)\n",
        "            self.ax.scatter(wake_pos[0], wake_pos[1], color='blue', alpha=alpha, s=marker_size, marker='o')\n",
        "\n",
        "        return self.ax\n",
        "\n",
        "    def create_video(self, ic=InitialCondition(distance=30, f2=1.), time=10):\n",
        "        airfoil_path = self.naca_airfoil(\"0016\")\n",
        "        state = self.env.reset(ic)\n",
        "\n",
        "        self.fish_marker = MarkerStyle(airfoil_path, transform=mpl.transforms.Affine2D().scale(16))\n",
        "\n",
        "        self.leader_positions = []\n",
        "        self.follower_positions = []\n",
        "        frame_rate = 12\n",
        "        runtime = time # seconds\n",
        "\n",
        "        self.v_flow_history = []\n",
        "\n",
        "        for _ in range(frame_rate*runtime):\n",
        "            action = self.ppo.policy.act(state, Memory())\n",
        "            state, reward, done, info = self.env.step(action)\n",
        "\n",
        "            self.leader_positions.append((info['x1'], info['y1']))\n",
        "            self.follower_positions.append((info['x2'], info['y2']))\n",
        "            self.v_flow_history.append(info['v_flow'])\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        fig, self.ax = plt.subplots(figsize=(21, 9))\n",
        "        ani = animation.FuncAnimation(fig, self.animate, frames=len(self.leader_positions), interval=frame_rate, blit=False)\n",
        "\n",
        "        # To save the animation as a video file:\n",
        "        ani.save('swimmer_animation.mp4', writer='ffmpeg', fps=frame_rate)\n",
        "\n",
        "        # Plot distances\n",
        "        distances = [numpy.linalg.norm(numpy.array(leader_pos) - numpy.array(follower_pos))\n",
        "                    for leader_pos, follower_pos in zip(self.leader_positions, self.follower_positions)]\n",
        "        times = numpy.arange(len(distances)) * (1.0 / frame_rate)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(times, distances)\n",
        "        plt.xlabel('Time (seconds)')\n",
        "        plt.ylabel('Distance')\n",
        "        plt.title('Distance between Leader and Follower vs. Time')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        return;"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL CONTROL**"
      ],
      "metadata": {
        "id": "4WJ5ECTGRw75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Full run\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "obs_action = ['f2','A2']\n",
        "obs_flow = ['distance', 'flow agreement', 'avg flow agreement', 'velocity']\n",
        "rewards = ['distance', 'flow agreement', 'avg flow agreement', 'velocity', 'flow acceleration']\n",
        "\n",
        "for obs1 in obs_action:\n",
        "  for obs2 in obs_flow:\n",
        "    for rew in rewards:\n",
        "      trainer = Trainer(\n",
        "          action=obs1,  # None, 'f2', or 'A2'\n",
        "          observations=[obs1, obs2],  # may contain: 'distance', 'f2', 'A2', 'flow\n",
        "          rewards=[rew],  # may contain: 'distance', 'flow agreement'\n",
        "      )\n",
        "      icfn = lambda: InitialCondition().random([obs1,'distance'])\n",
        "      trainer.train(initial_condition_fn=icfn, episodes=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbD6nUGvhm4z",
        "outputId": "cf9d8779-4c54-477e-ee45-771530689c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 20 \t avg length: 95 \t reward: -132.88601228757284\n",
            "Episode 40 \t avg length: 188 \t reward: -129.1626973269726\n",
            "Episode 60 \t avg length: 334 \t reward: -74.3735987682725\n",
            "Episode 80 \t avg length: 459 \t reward: -10.422850501829704\n",
            "Episode 100 \t avg length: 499 \t reward: 2.855655877151835\n",
            "Episode 120 \t avg length: 499 \t reward: 2.519740572844274\n",
            "Episode 140 \t avg length: 499 \t reward: 3.689719838591465\n",
            "Episode 160 \t avg length: 499 \t reward: 2.964915158569391\n",
            "Episode 180 \t avg length: 499 \t reward: 4.09467817958923\n",
            "Episode 200 \t avg length: 499 \t reward: 3.441144890539428\n",
            "Episode 220 \t avg length: 499 \t reward: 4.444648439548666\n",
            "Episode 240 \t avg length: 499 \t reward: 3.5695686178016524\n",
            "Episode 260 \t avg length: 499 \t reward: 4.388426462804251\n",
            "Episode 280 \t avg length: 499 \t reward: 3.565542967302367\n",
            "Episode 300 \t avg length: 499 \t reward: 3.8298260641693154\n",
            "Episode 320 \t avg length: 499 \t reward: 3.1751369384517423\n",
            "Episode 340 \t avg length: 499 \t reward: 5.623055098512272\n",
            "Episode 360 \t avg length: 499 \t reward: 4.487671005251237\n",
            "Episode 380 \t avg length: 499 \t reward: 4.997847042633055\n",
            "Episode 400 \t avg length: 499 \t reward: 4.3071348161611365\n",
            "Episode 420 \t avg length: 499 \t reward: 3.0763404577997804\n",
            "Episode 440 \t avg length: 499 \t reward: 2.8892186156268105\n",
            "Episode 460 \t avg length: 499 \t reward: 3.7095332508875543\n",
            "Episode 480 \t avg length: 499 \t reward: 3.3185079086492046\n",
            "Episode 500 \t avg length: 499 \t reward: 4.912527529214281\n",
            "Episode 520 \t avg length: 499 \t reward: 5.017088511719798\n",
            "Episode 540 \t avg length: 499 \t reward: 3.8047137712689088\n",
            "Episode 560 \t avg length: 499 \t reward: 4.273572665321828\n",
            "Episode 580 \t avg length: 499 \t reward: 4.724383610662814\n",
            "Episode 600 \t avg length: 499 \t reward: 3.4194181333346187\n",
            "Episode 620 \t avg length: 499 \t reward: 5.197212685166254\n",
            "Episode 640 \t avg length: 499 \t reward: 4.5994839796806115\n",
            "Episode 660 \t avg length: 499 \t reward: 4.209476045538504\n",
            "Episode 680 \t avg length: 499 \t reward: 5.187321904930271\n",
            "Episode 700 \t avg length: 499 \t reward: 3.0872845991553777\n",
            "Episode 720 \t avg length: 499 \t reward: 3.0238457505749663\n",
            "Episode 740 \t avg length: 499 \t reward: 4.15872814978939\n",
            "Episode 760 \t avg length: 499 \t reward: 4.112417001429991\n",
            "Episode 780 \t avg length: 499 \t reward: 5.272148885013145\n",
            "Episode 800 \t avg length: 499 \t reward: 3.674964549848737\n",
            "Episode 820 \t avg length: 499 \t reward: 5.3427298798283465\n",
            "Episode 840 \t avg length: 499 \t reward: 4.6144177254356835\n",
            "Episode 860 \t avg length: 499 \t reward: 4.617455282942265\n",
            "Episode 880 \t avg length: 499 \t reward: 4.405229152589634\n",
            "Episode 900 \t avg length: 499 \t reward: 4.317705849940479\n",
            "Episode 920 \t avg length: 499 \t reward: 5.451889258769304\n",
            "Episode 940 \t avg length: 499 \t reward: 4.462134093228592\n",
            "Episode 960 \t avg length: 499 \t reward: 5.891568620426383\n",
            "Episode 980 \t avg length: 499 \t reward: 4.061519449080523\n",
            "Episode 1000 \t avg length: 499 \t reward: 3.918099141646347\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20 \t avg length: 101 \t reward: -95.1621351047177\n",
            "Episode 40 \t avg length: 106 \t reward: -78.85083651211694\n",
            "Episode 60 \t avg length: 113 \t reward: -77.17316521615383\n",
            "Episode 80 \t avg length: 97 \t reward: -70.291882045616\n",
            "Episode 100 \t avg length: 84 \t reward: -89.83056391886343\n",
            "Episode 120 \t avg length: 109 \t reward: -83.93643180961107\n",
            "Episode 140 \t avg length: 110 \t reward: -81.39490980472962\n",
            "Episode 160 \t avg length: 110 \t reward: -89.89219631799904\n",
            "Episode 180 \t avg length: 168 \t reward: -95.80102009583312\n",
            "Episode 200 \t avg length: 110 \t reward: -66.98139377933282\n",
            "Episode 220 \t avg length: 259 \t reward: -70.89234656313553\n",
            "Episode 240 \t avg length: 297 \t reward: -53.03999517132193\n",
            "Episode 260 \t avg length: 78 \t reward: -80.03100024302414\n",
            "Episode 280 \t avg length: 499 \t reward: 15.024253815875543\n",
            "Episode 300 \t avg length: 424 \t reward: -16.301019599715637\n",
            "Episode 320 \t avg length: 261 \t reward: -58.605902837296334\n",
            "Episode 340 \t avg length: 331 \t reward: -24.218161362005905\n",
            "Episode 360 \t avg length: 208 \t reward: -60.657968258043596\n",
            "Episode 380 \t avg length: 55 \t reward: -76.47078745363804\n",
            "Episode 400 \t avg length: 260 \t reward: -41.35717260118223\n",
            "Episode 420 \t avg length: 355 \t reward: -13.586181865988976\n",
            "Episode 440 \t avg length: 293 \t reward: -37.917525764802676\n",
            "Episode 460 \t avg length: 52 \t reward: -75.09649068916377\n",
            "Episode 480 \t avg length: 56 \t reward: -92.82406449195662\n",
            "Episode 500 \t avg length: 234 \t reward: -61.38056446395219\n",
            "Episode 520 \t avg length: 492 \t reward: 12.038954588493649\n",
            "Episode 540 \t avg length: 480 \t reward: 11.725247371057568\n",
            "Episode 560 \t avg length: 465 \t reward: -1.8555421504603071\n",
            "Episode 580 \t avg length: 499 \t reward: 16.5922018320775\n",
            "Episode 600 \t avg length: 499 \t reward: 16.430019186240816\n",
            "Episode 620 \t avg length: 477 \t reward: 6.704077919540336\n",
            "Episode 640 \t avg length: 409 \t reward: -17.28864520580595\n",
            "Episode 660 \t avg length: 443 \t reward: -7.726894448528339\n",
            "Episode 680 \t avg length: 463 \t reward: 1.7059428221060298\n",
            "Episode 700 \t avg length: 499 \t reward: 16.660187631885286\n",
            "Episode 720 \t avg length: 480 \t reward: 6.073712584902995\n",
            "Episode 740 \t avg length: 325 \t reward: -35.84557446694686\n",
            "Episode 760 \t avg length: 476 \t reward: 5.814439972719536\n",
            "Episode 780 \t avg length: 499 \t reward: 16.329729552248935\n",
            "Episode 800 \t avg length: 477 \t reward: 8.807187255520068\n",
            "Episode 820 \t avg length: 450 \t reward: 0.6869668245338155\n",
            "Episode 840 \t avg length: 498 \t reward: 11.392498645177074\n",
            "Episode 860 \t avg length: 491 \t reward: 11.767255517472403\n",
            "Episode 880 \t avg length: 423 \t reward: -18.35359799363495\n",
            "Episode 900 \t avg length: 499 \t reward: 16.671028255623305\n",
            "Episode 920 \t avg length: 493 \t reward: 11.642393942576492\n",
            "Episode 940 \t avg length: 499 \t reward: 16.984199937802007\n",
            "Episode 960 \t avg length: 474 \t reward: 6.638181325867306\n",
            "Episode 980 \t avg length: 411 \t reward: -5.673201221377406\n",
            "Episode 1000 \t avg length: 232 \t reward: -50.59082918508501\n",
            "Episode 20 \t avg length: 71 \t reward: -107.1471904883933\n",
            "Episode 40 \t avg length: 52 \t reward: -99.04430830174363\n",
            "Episode 60 \t avg length: 116 \t reward: -104.96793571741357\n",
            "Episode 80 \t avg length: 158 \t reward: -101.86981632003412\n",
            "Episode 100 \t avg length: 213 \t reward: -108.23000412596681\n",
            "Episode 120 \t avg length: 75 \t reward: -102.61847751428472\n",
            "Episode 140 \t avg length: 91 \t reward: -93.65183108902364\n",
            "Episode 160 \t avg length: 154 \t reward: -104.69903295487737\n",
            "Episode 180 \t avg length: 114 \t reward: -110.81913302475411\n",
            "Episode 200 \t avg length: 201 \t reward: -79.94507182601892\n",
            "Episode 220 \t avg length: 140 \t reward: -109.10973652908285\n",
            "Episode 240 \t avg length: 127 \t reward: -103.52343797326986\n",
            "Episode 260 \t avg length: 318 \t reward: -75.74386683249352\n",
            "Episode 280 \t avg length: 270 \t reward: -75.68151964218761\n",
            "Episode 300 \t avg length: 111 \t reward: -99.75609571241537\n",
            "Episode 320 \t avg length: 122 \t reward: -107.20534557899866\n",
            "Episode 340 \t avg length: 414 \t reward: -46.216917483571265\n",
            "Episode 360 \t avg length: 352 \t reward: -41.29383053604959\n",
            "Episode 380 \t avg length: 381 \t reward: -36.39887189169073\n",
            "Episode 400 \t avg length: 271 \t reward: -100.81873495635188\n",
            "Episode 420 \t avg length: 312 \t reward: -64.69966102880589\n",
            "Episode 440 \t avg length: 266 \t reward: -86.34300694756777\n",
            "Episode 460 \t avg length: 437 \t reward: -22.912096355190773\n",
            "Episode 480 \t avg length: 499 \t reward: 3.285985056882082\n",
            "Episode 500 \t avg length: 412 \t reward: -29.921896256778275\n",
            "Episode 520 \t avg length: 130 \t reward: -88.08829856261545\n",
            "Episode 540 \t avg length: 423 \t reward: -24.687441380031775\n",
            "Episode 560 \t avg length: 412 \t reward: -37.330162762082935\n",
            "Episode 580 \t avg length: 481 \t reward: -4.576163427567641\n",
            "Episode 600 \t avg length: 466 \t reward: -30.144830665607525\n",
            "Episode 620 \t avg length: 403 \t reward: -25.305611672389862\n",
            "Episode 640 \t avg length: 393 \t reward: -93.86733482227064\n",
            "Episode 660 \t avg length: 478 \t reward: -62.314918557300814\n",
            "Episode 680 \t avg length: 422 \t reward: -59.39737946107505\n",
            "Episode 700 \t avg length: 499 \t reward: 2.4890438706399602\n",
            "Episode 720 \t avg length: 499 \t reward: -5.9887698438388055\n",
            "Episode 740 \t avg length: 499 \t reward: -1.214815693097805\n",
            "Episode 760 \t avg length: 479 \t reward: -6.754191898748718\n",
            "Episode 780 \t avg length: 316 \t reward: -60.43714031206446\n",
            "Episode 800 \t avg length: 296 \t reward: -66.89300289383817\n",
            "Episode 820 \t avg length: 495 \t reward: -4.844464820022091\n",
            "Episode 840 \t avg length: 351 \t reward: -42.903300231553786\n",
            "Episode 860 \t avg length: 423 \t reward: -28.74052312780686\n",
            "Episode 880 \t avg length: 356 \t reward: -39.70575706511792\n",
            "Episode 900 \t avg length: 428 \t reward: -50.21916842908837\n",
            "Episode 920 \t avg length: 413 \t reward: -95.78823856792663\n",
            "Episode 940 \t avg length: 256 \t reward: -86.84361102246021\n",
            "Episode 960 \t avg length: 499 \t reward: -13.878468871916388\n",
            "Episode 980 \t avg length: 426 \t reward: -24.504052992351117\n",
            "Episode 1000 \t avg length: 305 \t reward: -73.75249069139377\n",
            "Episode 20 \t avg length: 41 \t reward: -372.67998716812025\n",
            "Episode 40 \t avg length: 80 \t reward: -555.4451957723772\n",
            "Episode 60 \t avg length: 96 \t reward: -664.8470489790374\n",
            "Episode 80 \t avg length: 32 \t reward: -291.1059842846802\n",
            "Episode 100 \t avg length: 22 \t reward: -240.49413987308444\n",
            "Episode 120 \t avg length: 18 \t reward: -225.18226687733264\n",
            "Episode 140 \t avg length: 20 \t reward: -218.318269342036\n",
            "Episode 160 \t avg length: 19 \t reward: -231.88223741765987\n",
            "Episode 180 \t avg length: 18 \t reward: -228.98646145700292\n",
            "Episode 200 \t avg length: 15 \t reward: -225.01509356532765\n",
            "Episode 220 \t avg length: 17 \t reward: -225.57853123990827\n",
            "Episode 240 \t avg length: 17 \t reward: -214.12239534468614\n",
            "Episode 260 \t avg length: 19 \t reward: -230.86732305411388\n",
            "Episode 280 \t avg length: 20 \t reward: -227.85627544932944\n",
            "Episode 300 \t avg length: 22 \t reward: -238.35850256410427\n",
            "Episode 320 \t avg length: 18 \t reward: -223.24302715154187\n",
            "Episode 340 \t avg length: 17 \t reward: -223.03780044818495\n",
            "Episode 360 \t avg length: 15 \t reward: -229.52517932780356\n",
            "Episode 380 \t avg length: 16 \t reward: -222.97072205580398\n",
            "Episode 400 \t avg length: 14 \t reward: -204.49623556583217\n",
            "Episode 420 \t avg length: 14 \t reward: -230.42108375803042\n",
            "Episode 440 \t avg length: 13 \t reward: -213.81734917363514\n",
            "Episode 460 \t avg length: 14 \t reward: -204.184778071523\n",
            "Episode 480 \t avg length: 13 \t reward: -199.6545094201162\n",
            "Episode 500 \t avg length: 14 \t reward: -210.1302175949208\n",
            "Episode 520 \t avg length: 14 \t reward: -216.09007833601567\n",
            "Episode 540 \t avg length: 14 \t reward: -212.4642805352919\n",
            "Episode 560 \t avg length: 14 \t reward: -206.99430288851485\n",
            "Episode 580 \t avg length: 14 \t reward: -216.37348060116202\n",
            "Episode 600 \t avg length: 14 \t reward: -193.2612597285549\n",
            "Episode 620 \t avg length: 13 \t reward: -205.3874990313036\n",
            "Episode 640 \t avg length: 15 \t reward: -221.06560468126085\n",
            "Episode 660 \t avg length: 15 \t reward: -220.57690739773307\n",
            "Episode 680 \t avg length: 12 \t reward: -203.18525000733888\n",
            "Episode 700 \t avg length: 16 \t reward: -228.66352169296903\n",
            "Episode 720 \t avg length: 15 \t reward: -210.69193325780662\n",
            "Episode 740 \t avg length: 15 \t reward: -213.45701135975872\n",
            "Episode 760 \t avg length: 14 \t reward: -213.98916499949905\n",
            "Episode 780 \t avg length: 16 \t reward: -213.57639379468705\n",
            "Episode 800 \t avg length: 16 \t reward: -230.1052262688641\n",
            "Episode 820 \t avg length: 18 \t reward: -215.5987327609988\n",
            "Episode 840 \t avg length: 14 \t reward: -196.05148154029547\n",
            "Episode 860 \t avg length: 15 \t reward: -223.42007802508897\n",
            "Episode 880 \t avg length: 16 \t reward: -222.76001313032125\n",
            "Episode 900 \t avg length: 15 \t reward: -195.67209634371622\n",
            "Episode 920 \t avg length: 15 \t reward: -211.18321461811834\n",
            "Episode 940 \t avg length: 17 \t reward: -220.9763254461421\n",
            "Episode 960 \t avg length: 15 \t reward: -222.79971888400127\n",
            "Episode 980 \t avg length: 14 \t reward: -208.94960016987648\n",
            "Episode 1000 \t avg length: 13 \t reward: -201.92632230581688\n",
            "Episode 20 \t avg length: 77 \t reward: -98.99098416474723\n",
            "Episode 40 \t avg length: 157 \t reward: -102.53412461245375\n",
            "Episode 60 \t avg length: 199 \t reward: -103.2147752130231\n",
            "Episode 80 \t avg length: 173 \t reward: -99.99042817829078\n",
            "Episode 100 \t avg length: 78 \t reward: -101.81121858354217\n",
            "Episode 120 \t avg length: 65 \t reward: -102.3083095039224\n",
            "Episode 140 \t avg length: 122 \t reward: -103.41255667798082\n",
            "Episode 160 \t avg length: 213 \t reward: -98.08722793408222\n",
            "Episode 180 \t avg length: 204 \t reward: -97.73017567030847\n",
            "Episode 200 \t avg length: 210 \t reward: -101.20110542007636\n",
            "Episode 220 \t avg length: 310 \t reward: -65.69418571270981\n",
            "Episode 240 \t avg length: 227 \t reward: -98.70453980599761\n",
            "Episode 260 \t avg length: 152 \t reward: -99.19472085357155\n",
            "Episode 280 \t avg length: 121 \t reward: -100.21031365858543\n",
            "Episode 300 \t avg length: 292 \t reward: -84.84289792641104\n",
            "Episode 320 \t avg length: 279 \t reward: -85.54707218217101\n",
            "Episode 340 \t avg length: 205 \t reward: -99.99991732902397\n",
            "Episode 360 \t avg length: 266 \t reward: -83.87743752626014\n",
            "Episode 380 \t avg length: 286 \t reward: -68.32792506164846\n",
            "Episode 400 \t avg length: 179 \t reward: -98.2404862035467\n",
            "Episode 420 \t avg length: 106 \t reward: -104.85530155255897\n",
            "Episode 440 \t avg length: 221 \t reward: -99.51243881547528\n",
            "Episode 460 \t avg length: 270 \t reward: -90.20901137445443\n",
            "Episode 480 \t avg length: 309 \t reward: -63.37009373569661\n",
            "Episode 500 \t avg length: 366 \t reward: -61.39182149225731\n",
            "Episode 520 \t avg length: 398 \t reward: -39.967542289857974\n",
            "Episode 540 \t avg length: 254 \t reward: -99.67215365276908\n",
            "Episode 560 \t avg length: 226 \t reward: -97.0295110471215\n",
            "Episode 580 \t avg length: 219 \t reward: -99.64723332164817\n",
            "Episode 600 \t avg length: 136 \t reward: -100.45842418668494\n",
            "Episode 620 \t avg length: 277 \t reward: -74.26665589717645\n",
            "Episode 640 \t avg length: 422 \t reward: -37.232361952800446\n",
            "Episode 660 \t avg length: 316 \t reward: -60.21034286892022\n",
            "Episode 680 \t avg length: 388 \t reward: -65.05642909033166\n",
            "Episode 700 \t avg length: 466 \t reward: -15.076476095193275\n",
            "Episode 720 \t avg length: 480 \t reward: -14.940180194970925\n",
            "Episode 740 \t avg length: 354 \t reward: -70.23501365834836\n",
            "Episode 760 \t avg length: 432 \t reward: -43.630457958095676\n",
            "Episode 780 \t avg length: 405 \t reward: -45.85534433796496\n",
            "Episode 800 \t avg length: 415 \t reward: -59.98781091792964\n",
            "Episode 820 \t avg length: 374 \t reward: -54.92091865906036\n",
            "Episode 840 \t avg length: 443 \t reward: -27.683269706527277\n",
            "Episode 860 \t avg length: 449 \t reward: -19.0484923446987\n",
            "Episode 880 \t avg length: 452 \t reward: -21.294018635959105\n",
            "Episode 900 \t avg length: 477 \t reward: -19.725766624540437\n",
            "Episode 920 \t avg length: 417 \t reward: -39.541970708081045\n",
            "Episode 940 \t avg length: 408 \t reward: -57.272155190868716\n",
            "Episode 960 \t avg length: 379 \t reward: -58.10176012654424\n",
            "Episode 980 \t avg length: 391 \t reward: -69.89584006462889\n",
            "Episode 1000 \t avg length: 265 \t reward: -95.4948568970079\n",
            "Episode 20 \t avg length: 120 \t reward: -115.41295854073743\n",
            "Episode 40 \t avg length: 253 \t reward: -88.53374314088498\n",
            "Episode 60 \t avg length: 135 \t reward: -116.62255968558038\n",
            "Episode 80 \t avg length: 112 \t reward: -114.36156419692043\n",
            "Episode 100 \t avg length: 286 \t reward: -88.21100864741847\n",
            "Episode 120 \t avg length: 229 \t reward: -83.11568863684721\n",
            "Episode 140 \t avg length: 189 \t reward: -105.32167276486116\n",
            "Episode 160 \t avg length: 350 \t reward: -64.65838393600531\n",
            "Episode 180 \t avg length: 437 \t reward: -24.51985055651412\n",
            "Episode 200 \t avg length: 290 \t reward: -64.39290479480701\n",
            "Episode 220 \t avg length: 304 \t reward: -77.19057870519953\n",
            "Episode 240 \t avg length: 357 \t reward: -73.98356689905445\n",
            "Episode 260 \t avg length: 499 \t reward: 3.06155074917192\n",
            "Episode 280 \t avg length: 499 \t reward: -0.503464462181569\n",
            "Episode 300 \t avg length: 488 \t reward: -5.087157943558998\n",
            "Episode 320 \t avg length: 499 \t reward: 3.364504109267039\n",
            "Episode 340 \t avg length: 499 \t reward: 3.280934872014582\n",
            "Episode 360 \t avg length: 499 \t reward: 2.9502665150683725\n",
            "Episode 380 \t avg length: 479 \t reward: -3.7416778487356943\n",
            "Episode 400 \t avg length: 499 \t reward: 2.2978574109369605\n",
            "Episode 420 \t avg length: 499 \t reward: 2.607170003611098\n",
            "Episode 440 \t avg length: 499 \t reward: 2.4424648867035463\n",
            "Episode 460 \t avg length: 499 \t reward: 2.8493089642134573\n",
            "Episode 480 \t avg length: 499 \t reward: 3.429830913408318\n",
            "Episode 500 \t avg length: 499 \t reward: 2.1204500280522423\n",
            "Episode 520 \t avg length: 499 \t reward: 2.7979087570815615\n",
            "Episode 540 \t avg length: 499 \t reward: 3.0525545087046555\n",
            "Episode 560 \t avg length: 499 \t reward: 2.797602564245273\n",
            "Episode 580 \t avg length: 474 \t reward: -2.3628722561044144\n",
            "Episode 600 \t avg length: 499 \t reward: 3.7946910902078685\n",
            "Episode 620 \t avg length: 474 \t reward: -2.701856972273015\n",
            "Episode 640 \t avg length: 499 \t reward: 3.45449601975388\n",
            "Episode 660 \t avg length: 499 \t reward: 3.1263675912923703\n",
            "Episode 680 \t avg length: 499 \t reward: 2.087150964020503\n",
            "Episode 700 \t avg length: 499 \t reward: 2.4802273412124607\n",
            "Episode 720 \t avg length: 499 \t reward: 3.6682431508259525\n",
            "Episode 740 \t avg length: 473 \t reward: -8.53988874362722\n",
            "Episode 760 \t avg length: 475 \t reward: -2.301570357598583\n",
            "Episode 780 \t avg length: 499 \t reward: 3.2198717592309514\n",
            "Episode 800 \t avg length: 499 \t reward: 3.9237430289876807\n",
            "Episode 820 \t avg length: 499 \t reward: 3.9494210855358327\n",
            "Episode 840 \t avg length: 450 \t reward: -9.061705593564694\n",
            "Episode 860 \t avg length: 499 \t reward: 2.6173453152331962\n",
            "Episode 880 \t avg length: 499 \t reward: 1.5479113000064626\n",
            "Episode 900 \t avg length: 499 \t reward: 3.6632782577378853\n",
            "Episode 920 \t avg length: 499 \t reward: 4.163501512641219\n",
            "Episode 940 \t avg length: 499 \t reward: 2.9554830557727607\n",
            "Episode 960 \t avg length: 499 \t reward: 3.347367791419989\n",
            "Episode 980 \t avg length: 499 \t reward: 2.9938829520130286\n",
            "Episode 1000 \t avg length: 499 \t reward: 4.310087533220371\n",
            "Episode 20 \t avg length: 181 \t reward: -86.55241261088962\n",
            "Episode 40 \t avg length: 189 \t reward: -76.25024103965218\n",
            "Episode 60 \t avg length: 187 \t reward: -85.40771506740234\n",
            "Episode 80 \t avg length: 212 \t reward: -72.1170782976877\n",
            "Episode 100 \t avg length: 198 \t reward: -75.5616994011998\n",
            "Episode 120 \t avg length: 154 \t reward: -83.36808489693387\n",
            "Episode 140 \t avg length: 202 \t reward: -73.19506213340937\n",
            "Episode 160 \t avg length: 181 \t reward: -86.60580513437299\n",
            "Episode 180 \t avg length: 237 \t reward: -80.64749887798872\n",
            "Episode 200 \t avg length: 463 \t reward: -13.199789996386347\n",
            "Episode 220 \t avg length: 302 \t reward: -83.352899251969\n",
            "Episode 240 \t avg length: 369 \t reward: -36.65941937902647\n",
            "Episode 260 \t avg length: 362 \t reward: -24.44093813649383\n",
            "Episode 280 \t avg length: 396 \t reward: -16.398242573584486\n",
            "Episode 300 \t avg length: 426 \t reward: -28.664649656014614\n",
            "Episode 320 \t avg length: 479 \t reward: 2.1015481093048884\n",
            "Episode 340 \t avg length: 201 \t reward: -82.33726618664244\n",
            "Episode 360 \t avg length: 452 \t reward: -22.05809808881067\n",
            "Episode 380 \t avg length: 346 \t reward: -65.31865372870536\n",
            "Episode 400 \t avg length: 287 \t reward: -83.35289925181321\n",
            "Episode 420 \t avg length: 357 \t reward: -36.833506566185505\n",
            "Episode 440 \t avg length: 445 \t reward: -10.321551274967335\n",
            "Episode 460 \t avg length: 377 \t reward: -54.89115875954907\n",
            "Episode 480 \t avg length: 298 \t reward: -52.543820095555006\n",
            "Episode 500 \t avg length: 358 \t reward: -25.532558129027034\n",
            "Episode 520 \t avg length: 315 \t reward: -79.22567940090659\n",
            "Episode 540 \t avg length: 387 \t reward: -52.594937224516386\n",
            "Episode 560 \t avg length: 465 \t reward: -18.239614507177862\n",
            "Episode 580 \t avg length: 478 \t reward: 10.185822537567363\n",
            "Episode 600 \t avg length: 296 \t reward: -41.23203552212463\n",
            "Episode 620 \t avg length: 314 \t reward: -47.051423193400375\n",
            "Episode 640 \t avg length: 322 \t reward: -57.004390161545494\n",
            "Episode 660 \t avg length: 299 \t reward: -48.83740170608263\n",
            "Episode 680 \t avg length: 396 \t reward: -28.715949819513902\n",
            "Episode 700 \t avg length: 408 \t reward: -20.424086503805118\n",
            "Episode 720 \t avg length: 197 \t reward: -72.23002852373206\n",
            "Episode 740 \t avg length: 381 \t reward: -27.114836972585135\n",
            "Episode 760 \t avg length: 345 \t reward: -46.82733693312006\n",
            "Episode 780 \t avg length: 454 \t reward: 6.889818057385365\n",
            "Episode 800 \t avg length: 454 \t reward: 4.280278937629481\n",
            "Episode 820 \t avg length: 489 \t reward: 1.6470996620158076\n",
            "Episode 840 \t avg length: 363 \t reward: -28.513793805280756\n",
            "Episode 860 \t avg length: 403 \t reward: -67.02782866746354\n",
            "Episode 880 \t avg length: 322 \t reward: -64.81533715038776\n",
            "Episode 900 \t avg length: 288 \t reward: -83.35289925204361\n",
            "Episode 920 \t avg length: 318 \t reward: -84.10400425912178\n",
            "Episode 940 \t avg length: 340 \t reward: -83.45607324434067\n",
            "Episode 960 \t avg length: 458 \t reward: -11.392043941961655\n",
            "Episode 980 \t avg length: 499 \t reward: 16.665380330492816\n",
            "Episode 1000 \t avg length: 499 \t reward: 16.64622838400974\n",
            "Episode 20 \t avg length: 133 \t reward: -111.500063159875\n",
            "Episode 40 \t avg length: 141 \t reward: -93.54535943936789\n",
            "Episode 60 \t avg length: 96 \t reward: -80.06660460811338\n",
            "Episode 80 \t avg length: 41 \t reward: -70.3245204727564\n",
            "Episode 100 \t avg length: 27 \t reward: -69.88081622281614\n",
            "Episode 120 \t avg length: 28 \t reward: -65.60133020090515\n",
            "Episode 140 \t avg length: 23 \t reward: -60.03655593058549\n",
            "Episode 160 \t avg length: 23 \t reward: -65.49881902026075\n",
            "Episode 180 \t avg length: 21 \t reward: -75.77493165412751\n",
            "Episode 200 \t avg length: 19 \t reward: -69.96531804908427\n",
            "Episode 220 \t avg length: 20 \t reward: -61.33535806410316\n",
            "Episode 240 \t avg length: 20 \t reward: -83.0736567050866\n",
            "Episode 260 \t avg length: 29 \t reward: -54.96444032918337\n",
            "Episode 280 \t avg length: 21 \t reward: -73.60092903216429\n",
            "Episode 300 \t avg length: 23 \t reward: -59.42868521432681\n",
            "Episode 320 \t avg length: 33 \t reward: -80.82278557373226\n",
            "Episode 340 \t avg length: 76 \t reward: -50.2277214423328\n",
            "Episode 360 \t avg length: 141 \t reward: -69.9147565131577\n",
            "Episode 380 \t avg length: 217 \t reward: -75.90289171835198\n",
            "Episode 400 \t avg length: 147 \t reward: -72.73416447371925\n",
            "Episode 420 \t avg length: 64 \t reward: -65.87563217265007\n",
            "Episode 440 \t avg length: 198 \t reward: -87.942835384418\n",
            "Episode 460 \t avg length: 191 \t reward: -99.71737271882787\n",
            "Episode 480 \t avg length: 179 \t reward: -95.05546220191916\n",
            "Episode 500 \t avg length: 191 \t reward: -97.11351003755901\n",
            "Episode 520 \t avg length: 172 \t reward: -97.38237773876908\n",
            "Episode 540 \t avg length: 214 \t reward: -96.66806427085115\n",
            "Episode 560 \t avg length: 221 \t reward: -93.90855959174996\n",
            "Episode 580 \t avg length: 200 \t reward: -97.79048462359627\n",
            "Episode 600 \t avg length: 282 \t reward: -90.52179330558425\n",
            "Episode 620 \t avg length: 231 \t reward: -88.25211602991645\n",
            "Episode 640 \t avg length: 223 \t reward: -90.25570937152324\n",
            "Episode 660 \t avg length: 322 \t reward: -90.34895706957849\n",
            "Episode 680 \t avg length: 320 \t reward: -92.49860134738132\n",
            "Episode 700 \t avg length: 311 \t reward: -28.409549755204715\n",
            "Episode 720 \t avg length: 134 \t reward: -9.206775072160372\n",
            "Episode 740 \t avg length: 318 \t reward: 17.208563625245816\n",
            "Episode 760 \t avg length: 177 \t reward: -4.10426891751233\n",
            "Episode 780 \t avg length: 105 \t reward: -33.481958886448425\n",
            "Episode 800 \t avg length: 20 \t reward: -78.62543773967906\n",
            "Episode 820 \t avg length: 129 \t reward: -28.525412403580418\n",
            "Episode 840 \t avg length: 140 \t reward: -16.44594260706107\n",
            "Episode 860 \t avg length: 127 \t reward: -1.8704159545919663\n",
            "Episode 880 \t avg length: 307 \t reward: -10.965420662943803\n",
            "Episode 900 \t avg length: 419 \t reward: 8.760205370164666\n",
            "Episode 920 \t avg length: 385 \t reward: -15.217018930665944\n",
            "Episode 940 \t avg length: 318 \t reward: -87.84072843157229\n",
            "Episode 960 \t avg length: 422 \t reward: -53.370588093182974\n",
            "Episode 980 \t avg length: 273 \t reward: -17.156176832664947\n",
            "Episode 1000 \t avg length: 164 \t reward: -15.930283860913672\n",
            "Episode 20 \t avg length: 100 \t reward: -571.8191674719023\n",
            "Episode 40 \t avg length: 156 \t reward: -795.2430520109862\n",
            "Episode 60 \t avg length: 37 \t reward: -283.4907905426798\n",
            "Episode 80 \t avg length: 41 \t reward: -274.82603119660683\n",
            "Episode 100 \t avg length: 129 \t reward: -452.7937724812642\n",
            "Episode 120 \t avg length: 222 \t reward: -587.0696779912896\n",
            "Episode 140 \t avg length: 171 \t reward: -495.6730244270037\n",
            "Episode 160 \t avg length: 70 \t reward: -307.8674519525915\n",
            "Episode 180 \t avg length: 90 \t reward: -335.1966141887371\n",
            "Episode 200 \t avg length: 102 \t reward: -386.6738938393943\n",
            "Episode 220 \t avg length: 177 \t reward: -485.658430737776\n",
            "Episode 240 \t avg length: 132 \t reward: -372.00301501674636\n",
            "Episode 260 \t avg length: 58 \t reward: -271.9867257121832\n",
            "Episode 280 \t avg length: 56 \t reward: -293.7658237167426\n",
            "Episode 300 \t avg length: 70 \t reward: -306.11364888722386\n",
            "Episode 320 \t avg length: 62 \t reward: -320.6070105094079\n",
            "Episode 340 \t avg length: 82 \t reward: -346.3445362922607\n",
            "Episode 360 \t avg length: 72 \t reward: -301.4507267281591\n",
            "Episode 380 \t avg length: 29 \t reward: -229.24364835126715\n",
            "Episode 400 \t avg length: 88 \t reward: -336.7653158087161\n",
            "Episode 420 \t avg length: 101 \t reward: -294.48660132050867\n",
            "Episode 440 \t avg length: 96 \t reward: -358.2225167904955\n",
            "Episode 460 \t avg length: 82 \t reward: -319.89232973233936\n",
            "Episode 480 \t avg length: 83 \t reward: -308.39394700939687\n",
            "Episode 500 \t avg length: 48 \t reward: -280.7926759569045\n",
            "Episode 520 \t avg length: 45 \t reward: -241.50668459345147\n",
            "Episode 540 \t avg length: 46 \t reward: -265.9768698107185\n",
            "Episode 560 \t avg length: 37 \t reward: -263.01607390385067\n",
            "Episode 580 \t avg length: 39 \t reward: -259.8584338176675\n",
            "Episode 600 \t avg length: 21 \t reward: -238.7130672856973\n",
            "Episode 620 \t avg length: 30 \t reward: -235.16257427495333\n",
            "Episode 640 \t avg length: 27 \t reward: -238.2743603102164\n",
            "Episode 660 \t avg length: 19 \t reward: -213.40660814915972\n",
            "Episode 680 \t avg length: 19 \t reward: -205.31867853908784\n",
            "Episode 700 \t avg length: 24 \t reward: -234.93336553505947\n",
            "Episode 720 \t avg length: 39 \t reward: -251.26587112579378\n",
            "Episode 740 \t avg length: 32 \t reward: -245.79027452458664\n",
            "Episode 760 \t avg length: 33 \t reward: -253.54420664740366\n",
            "Episode 780 \t avg length: 30 \t reward: -252.84240702487227\n",
            "Episode 800 \t avg length: 41 \t reward: -252.887888079813\n",
            "Episode 820 \t avg length: 59 \t reward: -255.00850084586637\n",
            "Episode 840 \t avg length: 25 \t reward: -222.9539899824393\n",
            "Episode 860 \t avg length: 58 \t reward: -267.3334800382915\n",
            "Episode 880 \t avg length: 121 \t reward: -419.6484109444267\n",
            "Episode 900 \t avg length: 82 \t reward: -325.64442662972544\n",
            "Episode 920 \t avg length: 57 \t reward: -272.25387799944133\n",
            "Episode 940 \t avg length: 43 \t reward: -258.86413710035106\n",
            "Episode 960 \t avg length: 123 \t reward: -395.03552424533984\n",
            "Episode 980 \t avg length: 89 \t reward: -320.8071907249561\n",
            "Episode 1000 \t avg length: 78 \t reward: -296.64105760710584\n",
            "Episode 20 \t avg length: 194 \t reward: -85.00625959746193\n",
            "Episode 40 \t avg length: 191 \t reward: -90.09691135011508\n",
            "Episode 60 \t avg length: 160 \t reward: -87.10050535557073\n",
            "Episode 80 \t avg length: 211 \t reward: -85.43247472074003\n",
            "Episode 100 \t avg length: 184 \t reward: -89.44350460201339\n",
            "Episode 120 \t avg length: 274 \t reward: -77.43856202541667\n",
            "Episode 140 \t avg length: 286 \t reward: -79.77111115243908\n",
            "Episode 160 \t avg length: 271 \t reward: -69.98756682105281\n",
            "Episode 180 \t avg length: 254 \t reward: -62.674331968542845\n",
            "Episode 200 \t avg length: 224 \t reward: -94.20736291395136\n",
            "Episode 220 \t avg length: 277 \t reward: -67.8937736175998\n",
            "Episode 240 \t avg length: 334 \t reward: -65.49444478959097\n",
            "Episode 260 \t avg length: 341 \t reward: -58.24882093074342\n",
            "Episode 280 \t avg length: 287 \t reward: -85.241583169251\n",
            "Episode 300 \t avg length: 331 \t reward: -70.52947966959756\n",
            "Episode 320 \t avg length: 229 \t reward: -91.18431588437156\n",
            "Episode 340 \t avg length: 297 \t reward: -70.29925456629684\n",
            "Episode 360 \t avg length: 278 \t reward: -63.49702891151888\n",
            "Episode 380 \t avg length: 324 \t reward: -64.23017670705532\n",
            "Episode 400 \t avg length: 348 \t reward: -55.67491243272485\n",
            "Episode 420 \t avg length: 313 \t reward: -60.09781128855337\n",
            "Episode 440 \t avg length: 299 \t reward: -75.82316278431874\n",
            "Episode 460 \t avg length: 332 \t reward: -54.40915810276066\n",
            "Episode 480 \t avg length: 300 \t reward: -74.43981648492321\n",
            "Episode 500 \t avg length: 360 \t reward: -59.569308655454265\n",
            "Episode 520 \t avg length: 371 \t reward: -49.34493355878215\n",
            "Episode 540 \t avg length: 273 \t reward: -83.6849973310407\n",
            "Episode 560 \t avg length: 247 \t reward: -74.8416841431864\n",
            "Episode 580 \t avg length: 294 \t reward: -65.5772687529623\n",
            "Episode 600 \t avg length: 302 \t reward: -66.47086573153726\n",
            "Episode 620 \t avg length: 375 \t reward: -54.35490423898267\n",
            "Episode 640 \t avg length: 374 \t reward: -54.44821284003344\n",
            "Episode 660 \t avg length: 294 \t reward: -75.53156221795241\n",
            "Episode 680 \t avg length: 294 \t reward: -85.38055053838154\n",
            "Episode 700 \t avg length: 218 \t reward: -103.41610627947523\n",
            "Episode 720 \t avg length: 191 \t reward: -94.07395581119758\n",
            "Episode 740 \t avg length: 342 \t reward: -55.86501765066042\n",
            "Episode 760 \t avg length: 268 \t reward: -89.99999999849787\n",
            "Episode 780 \t avg length: 258 \t reward: -99.99999999989906\n",
            "Episode 800 \t avg length: 351 \t reward: -54.43743747058968\n",
            "Episode 820 \t avg length: 218 \t reward: -89.69786853661353\n",
            "Episode 840 \t avg length: 236 \t reward: -94.79679932310026\n",
            "Episode 860 \t avg length: 276 \t reward: -89.8365275302367\n",
            "Episode 880 \t avg length: 297 \t reward: -90.00000000069585\n",
            "Episode 900 \t avg length: 341 \t reward: -78.98973976475479\n",
            "Episode 920 \t avg length: 260 \t reward: -74.47578119748559\n",
            "Episode 940 \t avg length: 310 \t reward: -71.40653636568786\n",
            "Episode 960 \t avg length: 356 \t reward: -63.770850620849714\n",
            "Episode 980 \t avg length: 310 \t reward: -79.37487035532598\n",
            "Episode 1000 \t avg length: 308 \t reward: -80.4433852966902\n",
            "Episode 20 \t avg length: 58 \t reward: -117.11428465790365\n",
            "Episode 40 \t avg length: 97 \t reward: -125.8292198631686\n",
            "Episode 60 \t avg length: 146 \t reward: -114.72413716785934\n",
            "Episode 80 \t avg length: 189 \t reward: -112.95232163336509\n",
            "Episode 100 \t avg length: 184 \t reward: -119.98316948380128\n",
            "Episode 120 \t avg length: 155 \t reward: -116.95777872853053\n",
            "Episode 140 \t avg length: 248 \t reward: -107.29449957462603\n",
            "Episode 160 \t avg length: 247 \t reward: -105.5679019594889\n",
            "Episode 180 \t avg length: 157 \t reward: -102.64904272668181\n",
            "Episode 200 \t avg length: 235 \t reward: -87.81228278534154\n",
            "Episode 220 \t avg length: 379 \t reward: -55.89185221433879\n",
            "Episode 240 \t avg length: 377 \t reward: -73.67117998498665\n",
            "Episode 260 \t avg length: 212 \t reward: -106.21754725733392\n",
            "Episode 280 \t avg length: 239 \t reward: -99.29147221850172\n",
            "Episode 300 \t avg length: 204 \t reward: -111.7676512715295\n",
            "Episode 320 \t avg length: 173 \t reward: -112.29400091582075\n",
            "Episode 340 \t avg length: 228 \t reward: -105.36234620153064\n",
            "Episode 360 \t avg length: 420 \t reward: -42.31483630806158\n",
            "Episode 380 \t avg length: 352 \t reward: -59.90190742584323\n",
            "Episode 400 \t avg length: 278 \t reward: -93.74183962804145\n",
            "Episode 420 \t avg length: 448 \t reward: -48.48483134504775\n",
            "Episode 440 \t avg length: 499 \t reward: -13.690903268441328\n",
            "Episode 460 \t avg length: 452 \t reward: -51.07256345718829\n",
            "Episode 480 \t avg length: 318 \t reward: -76.28955536862689\n",
            "Episode 500 \t avg length: 222 \t reward: -98.85092015205085\n",
            "Episode 520 \t avg length: 339 \t reward: -77.34097039980416\n",
            "Episode 540 \t avg length: 290 \t reward: -95.19702532684313\n",
            "Episode 560 \t avg length: 359 \t reward: -70.91097005118135\n",
            "Episode 580 \t avg length: 305 \t reward: -70.99248250638524\n",
            "Episode 600 \t avg length: 412 \t reward: -42.73011406921735\n",
            "Episode 620 \t avg length: 265 \t reward: -106.52738497621917\n",
            "Episode 640 \t avg length: 149 \t reward: -116.61791918504059\n",
            "Episode 660 \t avg length: 120 \t reward: -117.39823414975208\n",
            "Episode 680 \t avg length: 264 \t reward: -89.89626957006733\n",
            "Episode 700 \t avg length: 203 \t reward: -118.34026400609875\n",
            "Episode 720 \t avg length: 222 \t reward: -100.40462472407748\n",
            "Episode 740 \t avg length: 246 \t reward: -107.25148711742384\n",
            "Episode 760 \t avg length: 149 \t reward: -109.82621344424145\n",
            "Episode 780 \t avg length: 130 \t reward: -118.76876179007479\n",
            "Episode 800 \t avg length: 205 \t reward: -104.5202655696703\n",
            "Episode 820 \t avg length: 238 \t reward: -100.69059411422815\n",
            "Episode 840 \t avg length: 156 \t reward: -116.66223207472433\n",
            "Episode 860 \t avg length: 324 \t reward: -78.53788263282911\n",
            "Episode 880 \t avg length: 160 \t reward: -117.41574085008816\n",
            "Episode 900 \t avg length: 320 \t reward: -93.82449298647336\n",
            "Episode 920 \t avg length: 217 \t reward: -112.11468345551543\n",
            "Episode 940 \t avg length: 197 \t reward: -116.99292224341862\n",
            "Episode 960 \t avg length: 395 \t reward: -60.229103747086754\n",
            "Episode 980 \t avg length: 204 \t reward: -105.93009005950216\n",
            "Episode 1000 \t avg length: 344 \t reward: -77.74967758742108\n",
            "Episode 20 \t avg length: 181 \t reward: -69.8509797037971\n",
            "Episode 40 \t avg length: 247 \t reward: -46.92694683177608\n",
            "Episode 60 \t avg length: 134 \t reward: -69.42732671093435\n",
            "Episode 80 \t avg length: 222 \t reward: -67.45037025740947\n",
            "Episode 100 \t avg length: 161 \t reward: -61.15196771292962\n",
            "Episode 120 \t avg length: 84 \t reward: -93.79992295188715\n",
            "Episode 140 \t avg length: 76 \t reward: -79.78651836196305\n",
            "Episode 160 \t avg length: 128 \t reward: -69.05644564404345\n",
            "Episode 180 \t avg length: 291 \t reward: -68.35327678275802\n",
            "Episode 200 \t avg length: 249 \t reward: -83.35289925167974\n",
            "Episode 220 \t avg length: 289 \t reward: -83.35289925170544\n",
            "Episode 240 \t avg length: 223 \t reward: -81.68518511665692\n",
            "Episode 260 \t avg length: 207 \t reward: -84.54215226174989\n",
            "Episode 280 \t avg length: 235 \t reward: -83.3528992515848\n",
            "Episode 300 \t avg length: 239 \t reward: -84.46938175880572\n",
            "Episode 320 \t avg length: 386 \t reward: -56.65341134384455\n",
            "Episode 340 \t avg length: 386 \t reward: -78.35289925149866\n",
            "Episode 360 \t avg length: 300 \t reward: -68.73716543821057\n",
            "Episode 380 \t avg length: 77 \t reward: -87.89942892547506\n",
            "Episode 400 \t avg length: 288 \t reward: -46.61704757906744\n",
            "Episode 420 \t avg length: 363 \t reward: -75.65766727526822\n",
            "Episode 440 \t avg length: 215 \t reward: -57.391718109742065\n",
            "Episode 460 \t avg length: 73 \t reward: -79.04286959432575\n",
            "Episode 480 \t avg length: 83 \t reward: -82.15129503473199\n",
            "Episode 500 \t avg length: 92 \t reward: -88.7932205358239\n",
            "Episode 520 \t avg length: 416 \t reward: -48.67983186597628\n",
            "Episode 540 \t avg length: 382 \t reward: -49.18741384350484\n",
            "Episode 560 \t avg length: 401 \t reward: -10.184644538363319\n",
            "Episode 580 \t avg length: 426 \t reward: -17.491279470060118\n",
            "Episode 600 \t avg length: 458 \t reward: -8.289107648732431\n",
            "Episode 620 \t avg length: 450 \t reward: -28.391454796761586\n",
            "Episode 640 \t avg length: 396 \t reward: -9.385504430324927\n",
            "Episode 660 \t avg length: 267 \t reward: -54.113191127478856\n",
            "Episode 680 \t avg length: 402 \t reward: -9.462163469462132\n",
            "Episode 700 \t avg length: 409 \t reward: -9.465623868380801\n",
            "Episode 720 \t avg length: 347 \t reward: -29.0414573232417\n",
            "Episode 740 \t avg length: 371 \t reward: -13.082542733963688\n",
            "Episode 760 \t avg length: 370 \t reward: -19.635900752968478\n",
            "Episode 780 \t avg length: 334 \t reward: -44.811892363168624\n",
            "Episode 800 \t avg length: 380 \t reward: -20.177423049011697\n",
            "Episode 820 \t avg length: 363 \t reward: -19.08684337451261\n",
            "Episode 840 \t avg length: 369 \t reward: -34.42508530132771\n",
            "Episode 860 \t avg length: 285 \t reward: -42.28190793034152\n",
            "Episode 880 \t avg length: 336 \t reward: -72.78720696226867\n",
            "Episode 900 \t avg length: 416 \t reward: -5.926139102406472\n",
            "Episode 920 \t avg length: 332 \t reward: -20.07406668892397\n",
            "Episode 940 \t avg length: 326 \t reward: -53.01928068351765\n",
            "Episode 960 \t avg length: 333 \t reward: -29.452707589133222\n",
            "Episode 980 \t avg length: 475 \t reward: 12.224173625743566\n",
            "Episode 1000 \t avg length: 429 \t reward: 1.0667420910898016\n",
            "Episode 20 \t avg length: 228 \t reward: -74.55142237767004\n",
            "Episode 40 \t avg length: 109 \t reward: -96.88006934114492\n",
            "Episode 60 \t avg length: 274 \t reward: -72.06916768824793\n",
            "Episode 80 \t avg length: 315 \t reward: -73.11503536744684\n",
            "Episode 100 \t avg length: 205 \t reward: -94.48651676719098\n",
            "Episode 120 \t avg length: 129 \t reward: -97.8188591515728\n",
            "Episode 140 \t avg length: 204 \t reward: -99.70912004940816\n",
            "Episode 160 \t avg length: 165 \t reward: -86.25862043070244\n",
            "Episode 180 \t avg length: 152 \t reward: -91.27951011231163\n",
            "Episode 200 \t avg length: 121 \t reward: -46.32955699248479\n",
            "Episode 220 \t avg length: 168 \t reward: -3.2646778295504233\n",
            "Episode 240 \t avg length: 280 \t reward: -25.000229777562147\n",
            "Episode 260 \t avg length: 356 \t reward: -25.394569851569162\n",
            "Episode 280 \t avg length: 182 \t reward: 5.765080459899215\n",
            "Episode 300 \t avg length: 356 \t reward: 16.80027428174305\n",
            "Episode 320 \t avg length: 385 \t reward: 46.31032937545585\n",
            "Episode 340 \t avg length: 325 \t reward: 10.54937468137342\n",
            "Episode 360 \t avg length: 95 \t reward: -33.68427936354546\n",
            "Episode 380 \t avg length: 251 \t reward: -3.668383739998126\n",
            "Episode 400 \t avg length: 283 \t reward: -1.769614444769082\n",
            "Episode 420 \t avg length: 405 \t reward: 31.09034784290577\n",
            "Episode 440 \t avg length: 312 \t reward: 36.37247428716996\n",
            "Episode 460 \t avg length: 226 \t reward: -12.22103207513086\n",
            "Episode 480 \t avg length: 236 \t reward: -32.07019677785682\n",
            "Episode 500 \t avg length: 339 \t reward: 58.36782847898506\n",
            "Episode 520 \t avg length: 363 \t reward: 63.78975618275367\n",
            "Episode 540 \t avg length: 247 \t reward: 54.36247455232395\n",
            "Episode 560 \t avg length: 197 \t reward: 10.12167847456998\n",
            "Episode 580 \t avg length: 357 \t reward: 41.525955011261615\n",
            "Episode 600 \t avg length: 426 \t reward: 63.13956252593972\n",
            "Episode 620 \t avg length: 451 \t reward: 35.318110981875606\n",
            "Episode 640 \t avg length: 405 \t reward: 44.09968174690685\n",
            "Episode 660 \t avg length: 408 \t reward: -4.247875116638089\n",
            "Episode 680 \t avg length: 440 \t reward: 65.47071636585983\n",
            "Episode 700 \t avg length: 417 \t reward: -5.413452222482947\n",
            "Episode 720 \t avg length: 213 \t reward: -70.52268669712323\n",
            "Episode 740 \t avg length: 388 \t reward: -25.776075185596376\n",
            "Episode 760 \t avg length: 446 \t reward: -8.799341407651813\n",
            "Episode 780 \t avg length: 449 \t reward: -1.8182341770103965\n",
            "Episode 800 \t avg length: 386 \t reward: 14.750544537179206\n",
            "Episode 820 \t avg length: 311 \t reward: 30.611151701165664\n",
            "Episode 840 \t avg length: 324 \t reward: 66.67909329190041\n",
            "Episode 860 \t avg length: 283 \t reward: 100.1830683355149\n",
            "Episode 880 \t avg length: 167 \t reward: 25.322702002797758\n",
            "Episode 900 \t avg length: 126 \t reward: -5.211087227344154\n",
            "Episode 920 \t avg length: 167 \t reward: 31.31742976257525\n",
            "Episode 940 \t avg length: 144 \t reward: 7.021730606521851\n",
            "Episode 960 \t avg length: 150 \t reward: -26.256042015710317\n",
            "Episode 980 \t avg length: 84 \t reward: -13.252056302242414\n",
            "Episode 1000 \t avg length: 196 \t reward: 23.30713025889966\n",
            "Episode 20 \t avg length: 84 \t reward: -699.0335996333733\n",
            "Episode 40 \t avg length: 196 \t reward: -1283.8924587551078\n",
            "Episode 60 \t avg length: 254 \t reward: -609.0648798046717\n",
            "Episode 80 \t avg length: 106 \t reward: -425.518888520107\n",
            "Episode 100 \t avg length: 61 \t reward: -313.0762637419221\n",
            "Episode 120 \t avg length: 55 \t reward: -300.81591122720044\n",
            "Episode 140 \t avg length: 149 \t reward: -476.06251542040206\n",
            "Episode 160 \t avg length: 185 \t reward: -530.0737380604558\n",
            "Episode 180 \t avg length: 312 \t reward: -715.0825697604993\n",
            "Episode 200 \t avg length: 196 \t reward: -540.2286889422735\n",
            "Episode 220 \t avg length: 351 \t reward: -765.6778088667596\n",
            "Episode 240 \t avg length: 252 \t reward: -695.396534107544\n",
            "Episode 260 \t avg length: 186 \t reward: -493.636195840544\n",
            "Episode 280 \t avg length: 450 \t reward: -750.8882878370952\n",
            "Episode 300 \t avg length: 377 \t reward: -636.0902671143562\n",
            "Episode 320 \t avg length: 285 \t reward: -560.3861083990122\n",
            "Episode 340 \t avg length: 172 \t reward: -537.2951997559184\n",
            "Episode 360 \t avg length: 141 \t reward: -483.894640332379\n",
            "Episode 380 \t avg length: 321 \t reward: -593.1018496968857\n",
            "Episode 400 \t avg length: 383 \t reward: -627.4866182189475\n",
            "Episode 420 \t avg length: 349 \t reward: -492.17624769446354\n",
            "Episode 440 \t avg length: 412 \t reward: -380.57181357017294\n",
            "Episode 460 \t avg length: 325 \t reward: -432.7838729251372\n",
            "Episode 480 \t avg length: 210 \t reward: -382.87438588142066\n",
            "Episode 500 \t avg length: 430 \t reward: -429.53330875000074\n",
            "Episode 520 \t avg length: 391 \t reward: -429.1239954353362\n",
            "Episode 540 \t avg length: 370 \t reward: -446.2593154709906\n",
            "Episode 560 \t avg length: 365 \t reward: -506.15458615763436\n",
            "Episode 580 \t avg length: 310 \t reward: -474.61612054590535\n",
            "Episode 600 \t avg length: 342 \t reward: -418.3818417530638\n",
            "Episode 620 \t avg length: 237 \t reward: -455.1913038461839\n",
            "Episode 640 \t avg length: 276 \t reward: -542.2073552921204\n",
            "Episode 660 \t avg length: 396 \t reward: -453.5306913877066\n",
            "Episode 680 \t avg length: 455 \t reward: -301.6110797613599\n",
            "Episode 700 \t avg length: 333 \t reward: -286.15506073493714\n",
            "Episode 720 \t avg length: 324 \t reward: -291.48163150201174\n",
            "Episode 740 \t avg length: 311 \t reward: -312.22947194319363\n",
            "Episode 760 \t avg length: 311 \t reward: -349.1288817771241\n",
            "Episode 780 \t avg length: 369 \t reward: -443.6365767851539\n",
            "Episode 800 \t avg length: 265 \t reward: -354.65312450071417\n",
            "Episode 820 \t avg length: 240 \t reward: -328.2428555873408\n",
            "Episode 840 \t avg length: 253 \t reward: -349.3732357889865\n",
            "Episode 860 \t avg length: 376 \t reward: -291.4682183527662\n",
            "Episode 880 \t avg length: 385 \t reward: -394.50615154547984\n",
            "Episode 900 \t avg length: 365 \t reward: -343.9097382419243\n",
            "Episode 920 \t avg length: 334 \t reward: -332.8462530957911\n",
            "Episode 940 \t avg length: 270 \t reward: -287.3173023963149\n",
            "Episode 960 \t avg length: 263 \t reward: -306.69099924959363\n",
            "Episode 980 \t avg length: 275 \t reward: -331.1066552060347\n",
            "Episode 1000 \t avg length: 235 \t reward: -218.1478792850268\n",
            "Episode 20 \t avg length: 208 \t reward: -93.77411992136086\n",
            "Episode 40 \t avg length: 205 \t reward: -88.26051014380317\n",
            "Episode 60 \t avg length: 262 \t reward: -77.85081719523625\n",
            "Episode 80 \t avg length: 258 \t reward: -80.35927907915855\n",
            "Episode 100 \t avg length: 166 \t reward: -94.36188740888426\n",
            "Episode 120 \t avg length: 73 \t reward: -101.67958711660962\n",
            "Episode 140 \t avg length: 48 \t reward: -97.64957718785045\n",
            "Episode 160 \t avg length: 50 \t reward: -101.67278965642443\n",
            "Episode 180 \t avg length: 55 \t reward: -98.91733865572107\n",
            "Episode 200 \t avg length: 51 \t reward: -96.83344230958372\n",
            "Episode 220 \t avg length: 46 \t reward: -99.0487266941511\n",
            "Episode 240 \t avg length: 50 \t reward: -98.7238500563304\n",
            "Episode 260 \t avg length: 51 \t reward: -102.22417261790288\n",
            "Episode 280 \t avg length: 48 \t reward: -100.97722442459236\n",
            "Episode 300 \t avg length: 54 \t reward: -100.09687594223978\n",
            "Episode 320 \t avg length: 67 \t reward: -98.91179745133044\n",
            "Episode 340 \t avg length: 103 \t reward: -100.30323458096436\n",
            "Episode 360 \t avg length: 282 \t reward: -68.73881045435917\n",
            "Episode 380 \t avg length: 190 \t reward: -93.48904852718397\n",
            "Episode 400 \t avg length: 139 \t reward: -100.11051044657673\n",
            "Episode 420 \t avg length: 136 \t reward: -100.00687011500733\n",
            "Episode 440 \t avg length: 165 \t reward: -99.42916100743875\n",
            "Episode 460 \t avg length: 171 \t reward: -99.65582679442595\n",
            "Episode 480 \t avg length: 205 \t reward: -99.13913842147457\n",
            "Episode 500 \t avg length: 152 \t reward: -100.00000000020817\n",
            "Episode 520 \t avg length: 128 \t reward: -100.05540111600294\n",
            "Episode 540 \t avg length: 138 \t reward: -99.40282259433987\n",
            "Episode 560 \t avg length: 142 \t reward: -100.00000000063874\n",
            "Episode 580 \t avg length: 129 \t reward: -100.78486355792452\n",
            "Episode 600 \t avg length: 150 \t reward: -99.30616926014679\n",
            "Episode 620 \t avg length: 160 \t reward: -99.77907434000237\n",
            "Episode 640 \t avg length: 149 \t reward: -98.82684224152274\n",
            "Episode 660 \t avg length: 192 \t reward: -99.248716143851\n",
            "Episode 680 \t avg length: 328 \t reward: -85.54738570987529\n",
            "Episode 700 \t avg length: 310 \t reward: -83.8200289750969\n",
            "Episode 720 \t avg length: 421 \t reward: -34.45953068647523\n",
            "Episode 740 \t avg length: 317 \t reward: -67.76255044930454\n",
            "Episode 760 \t avg length: 371 \t reward: -48.67059670613503\n",
            "Episode 780 \t avg length: 399 \t reward: -35.62673328489747\n",
            "Episode 800 \t avg length: 373 \t reward: -39.60301757463229\n",
            "Episode 820 \t avg length: 278 \t reward: -90.79817608040364\n",
            "Episode 840 \t avg length: 349 \t reward: -36.48857594165178\n",
            "Episode 860 \t avg length: 259 \t reward: -64.42753992322284\n",
            "Episode 880 \t avg length: 131 \t reward: -88.93216588889265\n",
            "Episode 900 \t avg length: 119 \t reward: -100.41898952843717\n",
            "Episode 920 \t avg length: 91 \t reward: -102.43455585517464\n",
            "Episode 940 \t avg length: 105 \t reward: -98.30216077901747\n",
            "Episode 960 \t avg length: 145 \t reward: -75.46366000825982\n",
            "Episode 980 \t avg length: 230 \t reward: -100.13949687640611\n",
            "Episode 1000 \t avg length: 283 \t reward: -101.39669278392577\n",
            "Episode 20 \t avg length: 31 \t reward: -118.21961530931401\n",
            "Episode 40 \t avg length: 30 \t reward: -117.68128380533783\n",
            "Episode 60 \t avg length: 79 \t reward: -132.6940175118519\n",
            "Episode 80 \t avg length: 87 \t reward: -123.98005687053576\n",
            "Episode 100 \t avg length: 138 \t reward: -117.7496764864339\n",
            "Episode 120 \t avg length: 75 \t reward: -117.68324928832703\n",
            "Episode 140 \t avg length: 100 \t reward: -118.79341577914741\n",
            "Episode 160 \t avg length: 155 \t reward: -120.1787080688022\n",
            "Episode 180 \t avg length: 101 \t reward: -118.11876513305523\n",
            "Episode 200 \t avg length: 174 \t reward: -110.70207391091576\n",
            "Episode 220 \t avg length: 131 \t reward: -117.27049067825078\n",
            "Episode 240 \t avg length: 98 \t reward: -117.03679820799073\n",
            "Episode 260 \t avg length: 161 \t reward: -115.63023958811735\n",
            "Episode 280 \t avg length: 131 \t reward: -114.73495738885003\n",
            "Episode 300 \t avg length: 110 \t reward: -117.72799482140968\n",
            "Episode 320 \t avg length: 169 \t reward: -110.60400799491171\n",
            "Episode 340 \t avg length: 156 \t reward: -114.67464988950398\n",
            "Episode 360 \t avg length: 89 \t reward: -117.92178095846191\n",
            "Episode 380 \t avg length: 115 \t reward: -114.67702981880893\n",
            "Episode 400 \t avg length: 156 \t reward: -116.60605657497231\n",
            "Episode 420 \t avg length: 114 \t reward: -111.44605752734542\n",
            "Episode 440 \t avg length: 138 \t reward: -115.35243009049422\n",
            "Episode 460 \t avg length: 143 \t reward: -109.87600988196921\n",
            "Episode 480 \t avg length: 169 \t reward: -118.39534763367078\n",
            "Episode 500 \t avg length: 252 \t reward: -97.51706566830016\n",
            "Episode 520 \t avg length: 110 \t reward: -110.68588642824105\n",
            "Episode 540 \t avg length: 137 \t reward: -117.02239768862242\n",
            "Episode 560 \t avg length: 341 \t reward: -92.34560954103038\n",
            "Episode 580 \t avg length: 254 \t reward: -116.46018349179603\n",
            "Episode 600 \t avg length: 222 \t reward: -106.63673379606307\n",
            "Episode 620 \t avg length: 227 \t reward: -102.01284162703749\n",
            "Episode 640 \t avg length: 204 \t reward: -104.72237162466281\n",
            "Episode 660 \t avg length: 246 \t reward: -102.82408227595872\n",
            "Episode 680 \t avg length: 242 \t reward: -111.55739483684988\n",
            "Episode 700 \t avg length: 362 \t reward: -84.94595996114299\n",
            "Episode 720 \t avg length: 180 \t reward: -105.60209265475734\n",
            "Episode 740 \t avg length: 311 \t reward: -95.76210249848327\n",
            "Episode 760 \t avg length: 278 \t reward: -112.85655438237018\n",
            "Episode 780 \t avg length: 167 \t reward: -111.39421526520206\n",
            "Episode 800 \t avg length: 182 \t reward: -108.83400304794543\n",
            "Episode 820 \t avg length: 188 \t reward: -114.76955754135183\n",
            "Episode 840 \t avg length: 182 \t reward: -113.6690716986454\n",
            "Episode 860 \t avg length: 175 \t reward: -111.372066593265\n",
            "Episode 880 \t avg length: 231 \t reward: -107.2348316597402\n",
            "Episode 900 \t avg length: 263 \t reward: -96.85476211898188\n",
            "Episode 920 \t avg length: 325 \t reward: -88.33759425105764\n",
            "Episode 940 \t avg length: 213 \t reward: -94.12464084223649\n",
            "Episode 960 \t avg length: 297 \t reward: -100.75861746671217\n",
            "Episode 980 \t avg length: 326 \t reward: -82.41859124426956\n",
            "Episode 1000 \t avg length: 350 \t reward: -81.4163240588601\n",
            "Episode 20 \t avg length: 42 \t reward: -82.05191112153862\n",
            "Episode 40 \t avg length: 69 \t reward: -98.14245057128021\n",
            "Episode 60 \t avg length: 45 \t reward: -83.4148890877315\n",
            "Episode 80 \t avg length: 48 \t reward: -77.63836071305442\n",
            "Episode 100 \t avg length: 73 \t reward: -67.00351816731282\n",
            "Episode 120 \t avg length: 22 \t reward: -83.65975365790844\n",
            "Episode 140 \t avg length: 22 \t reward: -82.98514774887488\n",
            "Episode 160 \t avg length: 64 \t reward: -98.70018137889298\n",
            "Episode 180 \t avg length: 98 \t reward: -108.03742981398993\n",
            "Episode 200 \t avg length: 57 \t reward: -94.98387926153181\n",
            "Episode 220 \t avg length: 64 \t reward: -82.26710605759158\n",
            "Episode 240 \t avg length: 59 \t reward: -70.86397910351761\n",
            "Episode 260 \t avg length: 81 \t reward: -91.56090939271874\n",
            "Episode 280 \t avg length: 92 \t reward: -93.87243119645126\n",
            "Episode 300 \t avg length: 113 \t reward: -91.66619728194364\n",
            "Episode 320 \t avg length: 96 \t reward: -73.90306865755807\n",
            "Episode 340 \t avg length: 124 \t reward: -102.70110907186583\n",
            "Episode 360 \t avg length: 28 \t reward: -91.2886193909401\n",
            "Episode 380 \t avg length: 162 \t reward: -94.82933193386478\n",
            "Episode 400 \t avg length: 89 \t reward: -103.08976630551486\n",
            "Episode 420 \t avg length: 117 \t reward: -88.4328500284246\n",
            "Episode 440 \t avg length: 247 \t reward: -73.57994792954034\n",
            "Episode 460 \t avg length: 42 \t reward: -88.49096035275383\n",
            "Episode 480 \t avg length: 197 \t reward: -74.02171407129171\n",
            "Episode 500 \t avg length: 292 \t reward: -49.84100738370279\n",
            "Episode 520 \t avg length: 49 \t reward: -85.05484973990622\n",
            "Episode 540 \t avg length: 215 \t reward: -67.98478829540731\n",
            "Episode 560 \t avg length: 234 \t reward: -83.35289925187132\n",
            "Episode 580 \t avg length: 297 \t reward: -69.70754400628594\n",
            "Episode 600 \t avg length: 172 \t reward: -80.64728181735882\n",
            "Episode 620 \t avg length: 192 \t reward: -84.4757715149851\n",
            "Episode 640 \t avg length: 204 \t reward: -83.35289925188064\n",
            "Episode 660 \t avg length: 205 \t reward: -82.92817029203806\n",
            "Episode 680 \t avg length: 176 \t reward: -71.39335433619058\n",
            "Episode 700 \t avg length: 41 \t reward: -88.03716512254675\n",
            "Episode 720 \t avg length: 365 \t reward: -50.75981151992611\n",
            "Episode 740 \t avg length: 196 \t reward: -83.35289925159017\n",
            "Episode 760 \t avg length: 169 \t reward: -83.35289925173977\n",
            "Episode 780 \t avg length: 155 \t reward: -83.35289925169931\n",
            "Episode 800 \t avg length: 147 \t reward: -83.35289925178162\n",
            "Episode 820 \t avg length: 118 \t reward: -74.07200839931943\n",
            "Episode 840 \t avg length: 22 \t reward: -88.85256498068483\n",
            "Episode 860 \t avg length: 54 \t reward: -74.67653403540757\n",
            "Episode 880 \t avg length: 132 \t reward: -79.52643004955371\n",
            "Episode 900 \t avg length: 282 \t reward: -73.95996942044582\n",
            "Episode 920 \t avg length: 376 \t reward: -63.634948282750166\n",
            "Episode 940 \t avg length: 307 \t reward: -49.73226090117543\n",
            "Episode 960 \t avg length: 324 \t reward: -65.29576210346141\n",
            "Episode 980 \t avg length: 389 \t reward: -31.472893460852948\n",
            "Episode 1000 \t avg length: 420 \t reward: -29.68581156193013\n",
            "Episode 20 \t avg length: 66 \t reward: -105.01032171021215\n",
            "Episode 40 \t avg length: 194 \t reward: -93.66080667229099\n",
            "Episode 60 \t avg length: 198 \t reward: -107.73522109674767\n",
            "Episode 80 \t avg length: 184 \t reward: -118.60158415676972\n",
            "Episode 100 \t avg length: 106 \t reward: -103.34062613641895\n",
            "Episode 120 \t avg length: 181 \t reward: -107.13219611295578\n",
            "Episode 140 \t avg length: 137 \t reward: -114.59857447978773\n",
            "Episode 160 \t avg length: 137 \t reward: -70.00535908153691\n",
            "Episode 180 \t avg length: 153 \t reward: -100.0123601280588\n",
            "Episode 200 \t avg length: 179 \t reward: -86.10066693076291\n",
            "Episode 220 \t avg length: 220 \t reward: -104.99192628366859\n",
            "Episode 240 \t avg length: 251 \t reward: -91.77704305764277\n",
            "Episode 260 \t avg length: 252 \t reward: -72.48112685138027\n",
            "Episode 280 \t avg length: 234 \t reward: -116.0089730973007\n",
            "Episode 300 \t avg length: 249 \t reward: -108.9127757441732\n",
            "Episode 320 \t avg length: 228 \t reward: -146.2035924552253\n",
            "Episode 340 \t avg length: 76 \t reward: -96.26050048173138\n",
            "Episode 360 \t avg length: 74 \t reward: -103.67742680117385\n",
            "Episode 380 \t avg length: 206 \t reward: -112.73668995447572\n",
            "Episode 400 \t avg length: 150 \t reward: -88.45147103114164\n",
            "Episode 420 \t avg length: 150 \t reward: -117.43372223492982\n",
            "Episode 440 \t avg length: 245 \t reward: -112.33721235213356\n",
            "Episode 460 \t avg length: 181 \t reward: -135.31117271843323\n",
            "Episode 480 \t avg length: 150 \t reward: -118.85989207997356\n",
            "Episode 500 \t avg length: 210 \t reward: -95.70650912904904\n",
            "Episode 520 \t avg length: 242 \t reward: -89.46826195012582\n",
            "Episode 540 \t avg length: 303 \t reward: -77.02584049076081\n",
            "Episode 560 \t avg length: 298 \t reward: -110.79635030318795\n",
            "Episode 580 \t avg length: 367 \t reward: -62.51793247157265\n",
            "Episode 600 \t avg length: 156 \t reward: -127.0642077818515\n",
            "Episode 620 \t avg length: 197 \t reward: -102.93159502544992\n",
            "Episode 640 \t avg length: 268 \t reward: -90.71577988331555\n",
            "Episode 660 \t avg length: 340 \t reward: -90.1748914843205\n",
            "Episode 680 \t avg length: 246 \t reward: -101.69226515495123\n",
            "Episode 700 \t avg length: 204 \t reward: -96.02895990425678\n",
            "Episode 720 \t avg length: 167 \t reward: -93.70605089439462\n",
            "Episode 740 \t avg length: 232 \t reward: -94.46126696838003\n",
            "Episode 760 \t avg length: 296 \t reward: -133.4738704617043\n",
            "Episode 780 \t avg length: 52 \t reward: -105.38101179738953\n",
            "Episode 800 \t avg length: 71 \t reward: -123.92906456665128\n",
            "Episode 820 \t avg length: 196 \t reward: -143.7684840055141\n",
            "Episode 840 \t avg length: 208 \t reward: -97.73947406580575\n",
            "Episode 860 \t avg length: 168 \t reward: -102.16448326373508\n",
            "Episode 880 \t avg length: 208 \t reward: -86.48991346500841\n",
            "Episode 900 \t avg length: 349 \t reward: -63.32555787921909\n",
            "Episode 920 \t avg length: 393 \t reward: -92.41803869996198\n",
            "Episode 940 \t avg length: 291 \t reward: -89.97294475705607\n",
            "Episode 960 \t avg length: 260 \t reward: -92.8469858823009\n",
            "Episode 980 \t avg length: 171 \t reward: -130.24933115164484\n",
            "Episode 1000 \t avg length: 398 \t reward: -66.97976372122443\n",
            "Episode 20 \t avg length: 41 \t reward: -271.7931548709214\n",
            "Episode 40 \t avg length: 69 \t reward: -434.4056759554076\n",
            "Episode 60 \t avg length: 167 \t reward: -1291.031461022232\n",
            "Episode 80 \t avg length: 59 \t reward: -372.01574651227514\n",
            "Episode 100 \t avg length: 46 \t reward: -353.0761757592538\n",
            "Episode 120 \t avg length: 33 \t reward: -261.65168853798946\n",
            "Episode 140 \t avg length: 38 \t reward: -280.2366522937076\n",
            "Episode 160 \t avg length: 36 \t reward: -265.64288331148197\n",
            "Episode 180 \t avg length: 117 \t reward: -505.7855177084688\n",
            "Episode 200 \t avg length: 108 \t reward: -477.87117191690703\n",
            "Episode 220 \t avg length: 55 \t reward: -298.20105744501956\n",
            "Episode 240 \t avg length: 57 \t reward: -345.8615583402575\n",
            "Episode 260 \t avg length: 98 \t reward: -457.42112181381725\n",
            "Episode 280 \t avg length: 150 \t reward: -571.5299872895166\n",
            "Episode 300 \t avg length: 127 \t reward: -555.7914645647568\n",
            "Episode 320 \t avg length: 184 \t reward: -715.2189400690502\n",
            "Episode 340 \t avg length: 101 \t reward: -400.4792970747309\n",
            "Episode 360 \t avg length: 41 \t reward: -254.52517729007172\n",
            "Episode 380 \t avg length: 173 \t reward: -542.2199283848677\n",
            "Episode 400 \t avg length: 210 \t reward: -942.1184005395878\n",
            "Episode 420 \t avg length: 175 \t reward: -778.8382609052554\n",
            "Episode 440 \t avg length: 243 \t reward: -1051.6068875777087\n",
            "Episode 460 \t avg length: 348 \t reward: -1057.704191274223\n",
            "Episode 480 \t avg length: 202 \t reward: -851.2475781730946\n",
            "Episode 500 \t avg length: 272 \t reward: -775.8330352688421\n",
            "Episode 520 \t avg length: 269 \t reward: -867.4638841323713\n",
            "Episode 540 \t avg length: 267 \t reward: -883.4759473596936\n",
            "Episode 560 \t avg length: 210 \t reward: -769.6492694182484\n",
            "Episode 580 \t avg length: 190 \t reward: -564.4582208609265\n",
            "Episode 600 \t avg length: 172 \t reward: -503.85568130406165\n",
            "Episode 620 \t avg length: 261 \t reward: -631.2966998285278\n",
            "Episode 640 \t avg length: 228 \t reward: -661.9305032624455\n",
            "Episode 660 \t avg length: 275 \t reward: -786.5095530616566\n",
            "Episode 680 \t avg length: 264 \t reward: -1234.6307068305146\n",
            "Episode 700 \t avg length: 236 \t reward: -702.0533725988172\n",
            "Episode 720 \t avg length: 255 \t reward: -972.7218550938645\n",
            "Episode 740 \t avg length: 232 \t reward: -738.1145957896895\n",
            "Episode 760 \t avg length: 222 \t reward: -852.2805079867733\n",
            "Episode 780 \t avg length: 244 \t reward: -948.6761760594106\n",
            "Episode 800 \t avg length: 277 \t reward: -1230.9380975797794\n",
            "Episode 820 \t avg length: 270 \t reward: -1218.4898464104926\n",
            "Episode 840 \t avg length: 200 \t reward: -755.6332619304494\n",
            "Episode 860 \t avg length: 280 \t reward: -1034.4216182145146\n",
            "Episode 880 \t avg length: 320 \t reward: -1251.1715823411457\n",
            "Episode 900 \t avg length: 190 \t reward: -683.2027162159567\n",
            "Episode 920 \t avg length: 96 \t reward: -467.96831171263574\n",
            "Episode 940 \t avg length: 289 \t reward: -881.3754854949051\n",
            "Episode 960 \t avg length: 272 \t reward: -1036.5421573700714\n",
            "Episode 980 \t avg length: 125 \t reward: -506.0345478165893\n",
            "Episode 1000 \t avg length: 54 \t reward: -283.57168669684177\n",
            "Episode 20 \t avg length: 32 \t reward: -97.25107871041084\n",
            "Episode 40 \t avg length: 130 \t reward: -94.12323260476151\n",
            "Episode 60 \t avg length: 195 \t reward: -96.24490309751735\n",
            "Episode 80 \t avg length: 183 \t reward: -88.52440345210442\n",
            "Episode 100 \t avg length: 154 \t reward: -101.52596589551754\n",
            "Episode 120 \t avg length: 195 \t reward: -98.48981184164116\n",
            "Episode 140 \t avg length: 147 \t reward: -97.6451293330858\n",
            "Episode 160 \t avg length: 99 \t reward: -99.3163368873721\n",
            "Episode 180 \t avg length: 223 \t reward: -79.8931866411236\n",
            "Episode 200 \t avg length: 318 \t reward: -81.26611299354374\n",
            "Episode 220 \t avg length: 168 \t reward: -99.99999999979147\n",
            "Episode 240 \t avg length: 192 \t reward: -92.95367115678775\n",
            "Episode 260 \t avg length: 205 \t reward: -99.63433419955248\n",
            "Episode 280 \t avg length: 190 \t reward: -95.00000168795033\n",
            "Episode 300 \t avg length: 106 \t reward: -101.36517398965236\n",
            "Episode 320 \t avg length: 67 \t reward: -99.76310632106626\n",
            "Episode 340 \t avg length: 127 \t reward: -96.15424192669263\n",
            "Episode 360 \t avg length: 203 \t reward: -95.0425566852077\n",
            "Episode 380 \t avg length: 78 \t reward: -99.90613777649548\n",
            "Episode 400 \t avg length: 284 \t reward: -74.66417037917253\n",
            "Episode 420 \t avg length: 240 \t reward: -85.54958904685994\n",
            "Episode 440 \t avg length: 151 \t reward: -96.7546766157234\n",
            "Episode 460 \t avg length: 190 \t reward: -85.96345801875412\n",
            "Episode 480 \t avg length: 271 \t reward: -85.71563521679083\n",
            "Episode 500 \t avg length: 272 \t reward: -95.09146873820646\n",
            "Episode 520 \t avg length: 196 \t reward: -95.60227720320675\n",
            "Episode 540 \t avg length: 241 \t reward: -95.26541852913337\n",
            "Episode 560 \t avg length: 263 \t reward: -85.2114666732208\n",
            "Episode 580 \t avg length: 290 \t reward: -68.67449422700402\n",
            "Episode 600 \t avg length: 251 \t reward: -95.49853716679834\n",
            "Episode 620 \t avg length: 239 \t reward: -74.66765863348661\n",
            "Episode 640 \t avg length: 231 \t reward: -92.96500994516606\n",
            "Episode 660 \t avg length: 241 \t reward: -95.13420823160762\n",
            "Episode 680 \t avg length: 176 \t reward: -98.8706750536307\n",
            "Episode 700 \t avg length: 196 \t reward: -100.17473866682221\n",
            "Episode 720 \t avg length: 398 \t reward: -44.15304496748162\n",
            "Episode 740 \t avg length: 346 \t reward: -80.00000000861976\n",
            "Episode 760 \t avg length: 264 \t reward: -100.45283415794789\n",
            "Episode 780 \t avg length: 365 \t reward: -65.29495269698639\n",
            "Episode 800 \t avg length: 221 \t reward: -94.82680018363875\n",
            "Episode 820 \t avg length: 176 \t reward: -100.4346120753942\n",
            "Episode 840 \t avg length: 272 \t reward: -70.84661458340229\n",
            "Episode 860 \t avg length: 358 \t reward: -39.72460782455475\n",
            "Episode 880 \t avg length: 406 \t reward: -33.857511937981826\n",
            "Episode 900 \t avg length: 326 \t reward: -59.19489758469534\n",
            "Episode 920 \t avg length: 265 \t reward: -94.99999999860002\n",
            "Episode 940 \t avg length: 296 \t reward: -90.00000125330976\n",
            "Episode 960 \t avg length: 372 \t reward: -69.60414537922892\n",
            "Episode 980 \t avg length: 253 \t reward: -100.00000000007212\n",
            "Episode 1000 \t avg length: 210 \t reward: -97.24327181810276\n",
            "Episode 20 \t avg length: 111 \t reward: -116.46728447391384\n",
            "Episode 40 \t avg length: 217 \t reward: -126.00059781975429\n",
            "Episode 60 \t avg length: 329 \t reward: -97.1074327245037\n",
            "Episode 80 \t avg length: 499 \t reward: 3.7688948924241523\n",
            "Episode 100 \t avg length: 474 \t reward: -1.8150142953137092\n",
            "Episode 120 \t avg length: 499 \t reward: 5.154345891235108\n",
            "Episode 140 \t avg length: 499 \t reward: 6.140271302282019\n",
            "Episode 160 \t avg length: 474 \t reward: -1.2190100981850733\n",
            "Episode 180 \t avg length: 474 \t reward: -1.2674353034525287\n",
            "Episode 200 \t avg length: 474 \t reward: -2.222437760200223\n",
            "Episode 220 \t avg length: 499 \t reward: 2.4584411462353923\n",
            "Episode 240 \t avg length: 401 \t reward: -20.483222746517217\n",
            "Episode 260 \t avg length: 403 \t reward: -23.651889789610443\n",
            "Episode 280 \t avg length: 405 \t reward: -23.568670885019962\n",
            "Episode 300 \t avg length: 499 \t reward: -0.5917350197890323\n",
            "Episode 320 \t avg length: 474 \t reward: -2.423166962440554\n",
            "Episode 340 \t avg length: 499 \t reward: 4.541288078065998\n",
            "Episode 360 \t avg length: 499 \t reward: 5.586490245504614\n",
            "Episode 380 \t avg length: 499 \t reward: 3.9925525638250483\n",
            "Episode 400 \t avg length: 499 \t reward: 4.744227342016945\n",
            "Episode 420 \t avg length: 499 \t reward: 3.4452201896367045\n",
            "Episode 440 \t avg length: 474 \t reward: -1.714126285777867\n",
            "Episode 460 \t avg length: 474 \t reward: -1.1467892431245432\n",
            "Episode 480 \t avg length: 474 \t reward: -0.7119934116192249\n",
            "Episode 500 \t avg length: 499 \t reward: 4.390763971664598\n",
            "Episode 520 \t avg length: 474 \t reward: -1.3152380455222956\n",
            "Episode 540 \t avg length: 474 \t reward: -0.241898055540827\n",
            "Episode 560 \t avg length: 474 \t reward: -1.742285209318575\n",
            "Episode 580 \t avg length: 499 \t reward: 4.808199260599132\n",
            "Episode 600 \t avg length: 474 \t reward: -1.198912536059701\n",
            "Episode 620 \t avg length: 401 \t reward: -18.284709802546487\n",
            "Episode 640 \t avg length: 474 \t reward: -1.9766697172891068\n",
            "Episode 660 \t avg length: 499 \t reward: 3.8967584871465837\n",
            "Episode 680 \t avg length: 499 \t reward: 3.0879252790276484\n",
            "Episode 700 \t avg length: 450 \t reward: -8.789116480293988\n",
            "Episode 720 \t avg length: 499 \t reward: 4.384091818382778\n",
            "Episode 740 \t avg length: 499 \t reward: 4.5159744099042385\n",
            "Episode 760 \t avg length: 499 \t reward: 5.45123819263187\n",
            "Episode 780 \t avg length: 499 \t reward: 5.9601678112786285\n",
            "Episode 800 \t avg length: 499 \t reward: 5.104324775047947\n",
            "Episode 820 \t avg length: 499 \t reward: 3.9110844808014833\n",
            "Episode 840 \t avg length: 499 \t reward: 3.8101267424312004\n",
            "Episode 860 \t avg length: 499 \t reward: 4.621044136926959\n",
            "Episode 880 \t avg length: 474 \t reward: -1.6704938044243718\n",
            "Episode 900 \t avg length: 474 \t reward: -1.254445191852535\n",
            "Episode 920 \t avg length: 499 \t reward: 4.274919276510585\n",
            "Episode 940 \t avg length: 474 \t reward: -2.566117421028702\n",
            "Episode 960 \t avg length: 475 \t reward: -1.7851644287137483\n",
            "Episode 980 \t avg length: 474 \t reward: -2.038997097263681\n",
            "Episode 1000 \t avg length: 499 \t reward: 4.921927977109466\n",
            "Episode 20 \t avg length: 199 \t reward: -85.65790629191663\n",
            "Episode 40 \t avg length: 93 \t reward: -96.34384400325864\n",
            "Episode 60 \t avg length: 181 \t reward: -89.84741050902542\n",
            "Episode 80 \t avg length: 128 \t reward: -94.3533658517018\n",
            "Episode 100 \t avg length: 106 \t reward: -71.89157335899014\n",
            "Episode 120 \t avg length: 110 \t reward: -67.64820686466871\n",
            "Episode 140 \t avg length: 191 \t reward: -76.94302612851433\n",
            "Episode 160 \t avg length: 181 \t reward: -63.70247038007564\n",
            "Episode 180 \t avg length: 83 \t reward: -99.82352048263334\n",
            "Episode 200 \t avg length: 133 \t reward: -97.50330383561408\n",
            "Episode 220 \t avg length: 132 \t reward: -83.1266158037033\n",
            "Episode 240 \t avg length: 173 \t reward: -83.62532301313102\n",
            "Episode 260 \t avg length: 177 \t reward: -94.56232593300135\n",
            "Episode 280 \t avg length: 187 \t reward: -71.09359237537441\n",
            "Episode 300 \t avg length: 91 \t reward: -78.04876466360795\n",
            "Episode 320 \t avg length: 89 \t reward: -73.88273568339648\n",
            "Episode 340 \t avg length: 270 \t reward: -52.61186243273331\n",
            "Episode 360 \t avg length: 247 \t reward: -59.6353286762473\n",
            "Episode 380 \t avg length: 499 \t reward: 16.652915129873538\n",
            "Episode 400 \t avg length: 499 \t reward: 16.26333912287833\n",
            "Episode 420 \t avg length: 499 \t reward: 17.197898618407663\n",
            "Episode 440 \t avg length: 362 \t reward: -38.3340234707664\n",
            "Episode 460 \t avg length: 331 \t reward: -56.97249838762549\n",
            "Episode 480 \t avg length: 344 \t reward: -40.9780071427209\n",
            "Episode 500 \t avg length: 317 \t reward: -44.381008561132106\n",
            "Episode 520 \t avg length: 425 \t reward: -9.867365219730702\n",
            "Episode 540 \t avg length: 397 \t reward: -10.657830773996018\n",
            "Episode 560 \t avg length: 453 \t reward: 8.365764883999296\n",
            "Episode 580 \t avg length: 450 \t reward: 2.670276254449908\n",
            "Episode 600 \t avg length: 364 \t reward: -23.031243739069165\n",
            "Episode 620 \t avg length: 474 \t reward: 11.64304936871178\n",
            "Episode 640 \t avg length: 336 \t reward: -20.6841024539379\n",
            "Episode 660 \t avg length: 273 \t reward: -53.795654459536934\n",
            "Episode 680 \t avg length: 474 \t reward: 9.091872349275484\n",
            "Episode 700 \t avg length: 474 \t reward: 10.670431902737654\n",
            "Episode 720 \t avg length: 499 \t reward: 14.0721971706302\n",
            "Episode 740 \t avg length: 499 \t reward: 17.375030070817285\n",
            "Episode 760 \t avg length: 409 \t reward: -13.186620896374814\n",
            "Episode 780 \t avg length: 408 \t reward: -23.481688480605268\n",
            "Episode 800 \t avg length: 465 \t reward: 1.6746982441528655\n",
            "Episode 820 \t avg length: 499 \t reward: 16.73649793484895\n",
            "Episode 840 \t avg length: 474 \t reward: 10.997349628801024\n",
            "Episode 860 \t avg length: 474 \t reward: 10.250427976769226\n",
            "Episode 880 \t avg length: 474 \t reward: 10.918131294952932\n",
            "Episode 900 \t avg length: 474 \t reward: 11.131647885646048\n",
            "Episode 920 \t avg length: 474 \t reward: 10.526734041138464\n",
            "Episode 940 \t avg length: 499 \t reward: 16.723029151490387\n",
            "Episode 960 \t avg length: 450 \t reward: 5.978571465428964\n",
            "Episode 980 \t avg length: 499 \t reward: 16.647825967778395\n",
            "Episode 1000 \t avg length: 448 \t reward: 1.6506087863919088\n",
            "Episode 20 \t avg length: 167 \t reward: -97.12906108374581\n",
            "Episode 40 \t avg length: 174 \t reward: -90.42325796706893\n",
            "Episode 60 \t avg length: 247 \t reward: -83.42162454515889\n",
            "Episode 80 \t avg length: 283 \t reward: -97.15236880802216\n",
            "Episode 100 \t avg length: 287 \t reward: -67.83767578010276\n",
            "Episode 120 \t avg length: 471 \t reward: -6.936763498581516\n",
            "Episode 140 \t avg length: 202 \t reward: -89.2988751813044\n",
            "Episode 160 \t avg length: 174 \t reward: -100.93001221851588\n",
            "Episode 180 \t avg length: 251 \t reward: -92.95043776845372\n",
            "Episode 200 \t avg length: 180 \t reward: -101.07784593265244\n",
            "Episode 220 \t avg length: 186 \t reward: -113.01073733250328\n",
            "Episode 240 \t avg length: 215 \t reward: -99.8851477809625\n",
            "Episode 260 \t avg length: 176 \t reward: -91.70344103493062\n",
            "Episode 280 \t avg length: 206 \t reward: -91.16207006434\n",
            "Episode 300 \t avg length: 227 \t reward: -91.42817178556433\n",
            "Episode 320 \t avg length: 207 \t reward: -79.75244933709396\n",
            "Episode 340 \t avg length: 244 \t reward: -127.54270401361043\n",
            "Episode 360 \t avg length: 234 \t reward: -85.81176724484837\n",
            "Episode 380 \t avg length: 235 \t reward: -92.08925935303442\n",
            "Episode 400 \t avg length: 166 \t reward: -98.26835745686283\n",
            "Episode 420 \t avg length: 243 \t reward: -95.55973892556857\n",
            "Episode 440 \t avg length: 217 \t reward: -74.91188428886895\n",
            "Episode 460 \t avg length: 291 \t reward: -80.24665668980468\n",
            "Episode 480 \t avg length: 235 \t reward: -94.57818210438742\n",
            "Episode 500 \t avg length: 182 \t reward: -94.30432604907165\n",
            "Episode 520 \t avg length: 155 \t reward: -89.4172994967079\n",
            "Episode 540 \t avg length: 194 \t reward: -95.58934151334697\n",
            "Episode 560 \t avg length: 263 \t reward: -102.24112018317184\n",
            "Episode 580 \t avg length: 396 \t reward: -114.62393685263865\n",
            "Episode 600 \t avg length: 164 \t reward: -92.25761640141258\n",
            "Episode 620 \t avg length: 189 \t reward: -93.72997723259927\n",
            "Episode 640 \t avg length: 332 \t reward: -90.27281838786622\n",
            "Episode 660 \t avg length: 250 \t reward: -118.97534709960439\n",
            "Episode 680 \t avg length: 263 \t reward: 5.748643230683069\n",
            "Episode 700 \t avg length: 480 \t reward: 72.11489105530714\n",
            "Episode 720 \t avg length: 461 \t reward: 319.5594912757141\n",
            "Episode 740 \t avg length: 404 \t reward: 213.29953818342125\n",
            "Episode 760 \t avg length: 412 \t reward: 246.2732841894013\n",
            "Episode 780 \t avg length: 499 \t reward: 420.2319868885339\n",
            "########## Solved! ##########\n",
            "Episode 20 \t avg length: 110 \t reward: -407.4862378144496\n",
            "Episode 40 \t avg length: 68 \t reward: -433.0448690672064\n",
            "Episode 60 \t avg length: 64 \t reward: -476.0448883783027\n",
            "Episode 80 \t avg length: 65 \t reward: -459.7430149442351\n",
            "Episode 100 \t avg length: 33 \t reward: -290.8107767783321\n",
            "Episode 120 \t avg length: 41 \t reward: -339.66247729791263\n",
            "Episode 140 \t avg length: 41 \t reward: -297.5590586194708\n",
            "Episode 160 \t avg length: 44 \t reward: -295.53148052637664\n",
            "Episode 180 \t avg length: 208 \t reward: -1173.3070145860863\n",
            "Episode 200 \t avg length: 187 \t reward: -790.5434875219604\n",
            "Episode 220 \t avg length: 126 \t reward: -707.1596580976266\n",
            "Episode 240 \t avg length: 106 \t reward: -661.3945301575902\n",
            "Episode 260 \t avg length: 41 \t reward: -325.1416008065258\n",
            "Episode 280 \t avg length: 30 \t reward: -284.7827957529004\n",
            "Episode 300 \t avg length: 30 \t reward: -276.8675057456198\n",
            "Episode 320 \t avg length: 37 \t reward: -313.053329709014\n",
            "Episode 340 \t avg length: 30 \t reward: -266.07435762906863\n",
            "Episode 360 \t avg length: 35 \t reward: -266.7263625328192\n",
            "Episode 380 \t avg length: 44 \t reward: -308.5188428564994\n",
            "Episode 400 \t avg length: 67 \t reward: -359.5508154498845\n",
            "Episode 420 \t avg length: 98 \t reward: -640.1336077692401\n",
            "Episode 440 \t avg length: 41 \t reward: -290.30140478706994\n",
            "Episode 460 \t avg length: 36 \t reward: -283.03056574505956\n",
            "Episode 480 \t avg length: 40 \t reward: -285.7918238570825\n",
            "Episode 500 \t avg length: 122 \t reward: -606.5373802416595\n",
            "Episode 520 \t avg length: 123 \t reward: -646.2185352803892\n",
            "Episode 540 \t avg length: 78 \t reward: -502.53695265617625\n",
            "Episode 560 \t avg length: 44 \t reward: -334.25042487215353\n",
            "Episode 580 \t avg length: 42 \t reward: -313.9744635357471\n",
            "Episode 600 \t avg length: 43 \t reward: -334.71182392254866\n",
            "Episode 620 \t avg length: 55 \t reward: -354.3383683428775\n",
            "Episode 640 \t avg length: 53 \t reward: -378.3197098804714\n",
            "Episode 660 \t avg length: 40 \t reward: -304.9276551723641\n",
            "Episode 680 \t avg length: 34 \t reward: -284.670803295282\n",
            "Episode 700 \t avg length: 80 \t reward: -531.3434366941613\n",
            "Episode 720 \t avg length: 140 \t reward: -957.5090745470428\n",
            "Episode 740 \t avg length: 82 \t reward: -490.2757323839534\n",
            "Episode 760 \t avg length: 69 \t reward: -349.9803362063656\n",
            "Episode 780 \t avg length: 106 \t reward: -883.5003043541116\n",
            "Episode 800 \t avg length: 116 \t reward: -833.0179100763038\n",
            "Episode 820 \t avg length: 35 \t reward: -282.0011356576319\n",
            "Episode 840 \t avg length: 29 \t reward: -280.11266015573085\n",
            "Episode 860 \t avg length: 24 \t reward: -245.07104584679988\n",
            "Episode 880 \t avg length: 25 \t reward: -242.5609825014992\n",
            "Episode 900 \t avg length: 24 \t reward: -244.7076926056273\n",
            "Episode 920 \t avg length: 26 \t reward: -248.51551892252047\n",
            "Episode 940 \t avg length: 28 \t reward: -266.3387481551373\n",
            "Episode 960 \t avg length: 27 \t reward: -270.53940406514437\n",
            "Episode 980 \t avg length: 22 \t reward: -229.70810631475774\n",
            "Episode 1000 \t avg length: 24 \t reward: -250.74925263900263\n",
            "Episode 20 \t avg length: 208 \t reward: -102.10640738898016\n",
            "Episode 40 \t avg length: 151 \t reward: -103.70946939128915\n",
            "Episode 60 \t avg length: 143 \t reward: -99.70905829421886\n",
            "Episode 80 \t avg length: 143 \t reward: -99.11293283323046\n",
            "Episode 100 \t avg length: 83 \t reward: -106.23432736299432\n",
            "Episode 120 \t avg length: 76 \t reward: -103.89265084432145\n",
            "Episode 140 \t avg length: 83 \t reward: -100.64482309219343\n",
            "Episode 160 \t avg length: 185 \t reward: -93.59261505067225\n",
            "Episode 180 \t avg length: 150 \t reward: -99.68519454334839\n",
            "Episode 200 \t avg length: 222 \t reward: -98.73734694359025\n",
            "Episode 220 \t avg length: 118 \t reward: -102.34259111778557\n",
            "Episode 240 \t avg length: 156 \t reward: -96.27639594831443\n",
            "Episode 260 \t avg length: 126 \t reward: -92.18663965312645\n",
            "Episode 280 \t avg length: 120 \t reward: -100.93164534139642\n",
            "Episode 300 \t avg length: 181 \t reward: -91.43112141404072\n",
            "Episode 320 \t avg length: 169 \t reward: -99.2456282749204\n",
            "Episode 340 \t avg length: 185 \t reward: -93.35552775285962\n",
            "Episode 360 \t avg length: 105 \t reward: -100.42877744092866\n",
            "Episode 380 \t avg length: 368 \t reward: -39.58988427657311\n",
            "Episode 400 \t avg length: 299 \t reward: -58.62700861763155\n",
            "Episode 420 \t avg length: 307 \t reward: -68.267488052657\n",
            "Episode 440 \t avg length: 236 \t reward: -72.33767302336584\n",
            "Episode 460 \t avg length: 246 \t reward: -74.82457066640552\n",
            "Episode 480 \t avg length: 443 \t reward: -21.570841865360944\n",
            "Episode 500 \t avg length: 474 \t reward: -3.4545487201728924\n",
            "Episode 520 \t avg length: 474 \t reward: -3.582051539798185\n",
            "Episode 540 \t avg length: 499 \t reward: 0.9055657137160786\n",
            "Episode 560 \t avg length: 338 \t reward: -59.94917056028312\n",
            "Episode 580 \t avg length: 281 \t reward: -85.01166298350249\n",
            "Episode 600 \t avg length: 330 \t reward: -54.8656905684655\n",
            "Episode 620 \t avg length: 260 \t reward: -74.75805857628173\n",
            "Episode 640 \t avg length: 282 \t reward: -68.90395353020688\n",
            "Episode 660 \t avg length: 338 \t reward: -45.09132526696562\n",
            "Episode 680 \t avg length: 499 \t reward: 0.13842849571924715\n",
            "Episode 700 \t avg length: 474 \t reward: -4.4484169353623075\n",
            "Episode 720 \t avg length: 273 \t reward: -66.28246492645869\n",
            "Episode 740 \t avg length: 450 \t reward: -8.926458289623815\n",
            "Episode 760 \t avg length: 278 \t reward: -69.81197817655851\n",
            "Episode 780 \t avg length: 111 \t reward: -99.55304682462773\n",
            "Episode 800 \t avg length: 257 \t reward: -84.5464556596795\n",
            "Episode 820 \t avg length: 356 \t reward: -49.691061792029046\n",
            "Episode 840 \t avg length: 203 \t reward: -89.99814887488667\n",
            "Episode 860 \t avg length: 190 \t reward: -99.91237952937206\n",
            "Episode 880 \t avg length: 299 \t reward: -74.98091618753327\n",
            "Episode 900 \t avg length: 245 \t reward: -90.35367580645809\n",
            "Episode 920 \t avg length: 457 \t reward: -10.316299140330674\n",
            "Episode 940 \t avg length: 367 \t reward: -45.481830787520366\n",
            "Episode 960 \t avg length: 313 \t reward: -69.93356259668577\n",
            "Episode 980 \t avg length: 469 \t reward: -11.068884542867284\n",
            "Episode 1000 \t avg length: 499 \t reward: 1.1717518072070443\n",
            "Episode 20 \t avg length: 90 \t reward: -115.991882075451\n",
            "Episode 40 \t avg length: 93 \t reward: -117.07832538334146\n",
            "Episode 60 \t avg length: 363 \t reward: -50.745188501833695\n",
            "Episode 80 \t avg length: 267 \t reward: -75.89931764559826\n",
            "Episode 100 \t avg length: 376 \t reward: -47.05508209469387\n",
            "Episode 120 \t avg length: 232 \t reward: -81.37203475051642\n",
            "Episode 140 \t avg length: 284 \t reward: -76.32173142882039\n",
            "Episode 160 \t avg length: 475 \t reward: -6.511421020586921\n",
            "Episode 180 \t avg length: 479 \t reward: -7.679570321958484\n",
            "Episode 200 \t avg length: 373 \t reward: -53.38668388434412\n",
            "Episode 220 \t avg length: 474 \t reward: -8.12002991823448\n",
            "Episode 240 \t avg length: 453 \t reward: -14.41133187139432\n",
            "Episode 260 \t avg length: 499 \t reward: -2.6748607449242248\n",
            "Episode 280 \t avg length: 431 \t reward: -18.83364296539139\n",
            "Episode 300 \t avg length: 479 \t reward: -4.776305140616531\n",
            "Episode 320 \t avg length: 402 \t reward: -23.87736604274999\n",
            "Episode 340 \t avg length: 499 \t reward: -0.0026258818722859623\n",
            "Episode 360 \t avg length: 124 \t reward: -115.9215245287957\n",
            "Episode 380 \t avg length: 465 \t reward: -12.800016700721713\n",
            "Episode 400 \t avg length: 470 \t reward: -11.147215903679314\n",
            "Episode 420 \t avg length: 474 \t reward: -6.951052660478654\n",
            "Episode 440 \t avg length: 452 \t reward: -11.440799227934995\n",
            "Episode 460 \t avg length: 474 \t reward: -6.16908984496086\n",
            "Episode 480 \t avg length: 499 \t reward: -0.09050312528992759\n",
            "Episode 500 \t avg length: 453 \t reward: -12.607392154181593\n",
            "Episode 520 \t avg length: 217 \t reward: -75.44404263749541\n",
            "Episode 540 \t avg length: 415 \t reward: -23.38375920128326\n",
            "Episode 560 \t avg length: 450 \t reward: -11.734638684037169\n",
            "Episode 580 \t avg length: 374 \t reward: -36.09263347766493\n",
            "Episode 600 \t avg length: 365 \t reward: -90.81378191526869\n",
            "Episode 620 \t avg length: 346 \t reward: -128.20931763535756\n",
            "Episode 640 \t avg length: 368 \t reward: -88.02285391114783\n",
            "Episode 660 \t avg length: 292 \t reward: -154.75243461933806\n",
            "Episode 680 \t avg length: 330 \t reward: -125.76491319060969\n",
            "Episode 700 \t avg length: 346 \t reward: -127.75509225434912\n",
            "Episode 720 \t avg length: 291 \t reward: -153.01189592489624\n",
            "Episode 740 \t avg length: 339 \t reward: -90.53701599520166\n",
            "Episode 760 \t avg length: 309 \t reward: -148.63010738022803\n",
            "Episode 780 \t avg length: 364 \t reward: -136.05474704663894\n",
            "Episode 800 \t avg length: 309 \t reward: -143.7275233272939\n",
            "Episode 820 \t avg length: 361 \t reward: -134.3235181151171\n",
            "Episode 840 \t avg length: 156 \t reward: -138.10243551521768\n",
            "Episode 860 \t avg length: 259 \t reward: -187.21301538412973\n",
            "Episode 880 \t avg length: 286 \t reward: -201.8181530001037\n",
            "Episode 900 \t avg length: 286 \t reward: -228.0173604739336\n",
            "Episode 920 \t avg length: 287 \t reward: -162.74933709624673\n",
            "Episode 940 \t avg length: 292 \t reward: -185.44527441386998\n",
            "Episode 960 \t avg length: 313 \t reward: -190.20512779352242\n",
            "Episode 980 \t avg length: 310 \t reward: -157.1652726960638\n",
            "Episode 1000 \t avg length: 331 \t reward: -204.48522407622\n",
            "Episode 20 \t avg length: 167 \t reward: -86.83416561459543\n",
            "Episode 40 \t avg length: 225 \t reward: -84.71218627436252\n",
            "Episode 60 \t avg length: 210 \t reward: -81.82887097336284\n",
            "Episode 80 \t avg length: 189 \t reward: -83.62958793568839\n",
            "Episode 100 \t avg length: 235 \t reward: -68.45740219603368\n",
            "Episode 120 \t avg length: 178 \t reward: -80.68820335330392\n",
            "Episode 140 \t avg length: 289 \t reward: -59.92992718146262\n",
            "Episode 160 \t avg length: 222 \t reward: -85.72389150093827\n",
            "Episode 180 \t avg length: 218 \t reward: -83.35289925111627\n",
            "Episode 200 \t avg length: 166 \t reward: -83.803916826851\n",
            "Episode 220 \t avg length: 208 \t reward: -83.35289925115102\n",
            "Episode 240 \t avg length: 271 \t reward: -83.35289925102785\n",
            "Episode 260 \t avg length: 383 \t reward: -57.25055616413395\n",
            "Episode 280 \t avg length: 421 \t reward: -10.988981143710049\n",
            "Episode 300 \t avg length: 396 \t reward: -26.07444368105083\n",
            "Episode 320 \t avg length: 323 \t reward: -34.100925175302436\n",
            "Episode 340 \t avg length: 309 \t reward: -53.826659091219106\n",
            "Episode 360 \t avg length: 298 \t reward: -42.548448872534706\n",
            "Episode 380 \t avg length: 316 \t reward: -36.950951415267745\n",
            "Episode 400 \t avg length: 399 \t reward: -20.583346888668853\n",
            "Episode 420 \t avg length: 302 \t reward: -40.69713107400852\n",
            "Episode 440 \t avg length: 339 \t reward: -84.84035963332039\n",
            "Episode 460 \t avg length: 277 \t reward: -86.11902881719837\n",
            "Episode 480 \t avg length: 471 \t reward: 5.715556813963074\n",
            "Episode 500 \t avg length: 354 \t reward: -17.883106533718824\n",
            "Episode 520 \t avg length: 449 \t reward: 5.8253499445830155\n",
            "Episode 540 \t avg length: 475 \t reward: 11.671360693846763\n",
            "Episode 560 \t avg length: 402 \t reward: -7.026377487737901\n",
            "Episode 580 \t avg length: 354 \t reward: -59.97574982164895\n",
            "Episode 600 \t avg length: 291 \t reward: -84.32583989857584\n",
            "Episode 620 \t avg length: 197 \t reward: -84.86513199047705\n",
            "Episode 640 \t avg length: 161 \t reward: -84.9998883298024\n",
            "Episode 660 \t avg length: 171 \t reward: -83.35289925134558\n",
            "Episode 680 \t avg length: 179 \t reward: -83.43698233659376\n",
            "Episode 700 \t avg length: 160 \t reward: -88.98332081186477\n",
            "Episode 720 \t avg length: 178 \t reward: -85.3238956353749\n",
            "Episode 740 \t avg length: 167 \t reward: -85.19054802712714\n",
            "Episode 760 \t avg length: 176 \t reward: -84.60187807511957\n",
            "Episode 780 \t avg length: 189 \t reward: -84.95666655688389\n",
            "Episode 800 \t avg length: 163 \t reward: -91.24898776459841\n",
            "Episode 820 \t avg length: 199 \t reward: -84.53739844993409\n",
            "Episode 840 \t avg length: 224 \t reward: -83.35289925115936\n",
            "Episode 860 \t avg length: 203 \t reward: -90.53292152201206\n",
            "Episode 880 \t avg length: 268 \t reward: -84.61534885347535\n",
            "Episode 900 \t avg length: 309 \t reward: -83.45579996179607\n",
            "Episode 920 \t avg length: 380 \t reward: -44.27471102937523\n",
            "Episode 940 \t avg length: 414 \t reward: -5.187454127388514\n",
            "Episode 960 \t avg length: 442 \t reward: -1.9549683479566018\n",
            "Episode 980 \t avg length: 154 \t reward: -85.41314097869623\n",
            "Episode 1000 \t avg length: 374 \t reward: -27.967552056829696\n",
            "Episode 20 \t avg length: 163 \t reward: -94.93994011420838\n",
            "Episode 40 \t avg length: 226 \t reward: -83.53916879283335\n",
            "Episode 60 \t avg length: 164 \t reward: -104.59216846727558\n",
            "Episode 80 \t avg length: 150 \t reward: -83.73815171151568\n",
            "Episode 100 \t avg length: 163 \t reward: -101.96547288572555\n",
            "Episode 120 \t avg length: 144 \t reward: -97.41763526072292\n",
            "Episode 140 \t avg length: 170 \t reward: -97.4410898879585\n",
            "Episode 160 \t avg length: 178 \t reward: -102.98166758015626\n",
            "Episode 180 \t avg length: 179 \t reward: -99.7382390771461\n",
            "Episode 200 \t avg length: 200 \t reward: -98.47818169055292\n",
            "Episode 220 \t avg length: 174 \t reward: -99.72686749742054\n",
            "Episode 240 \t avg length: 168 \t reward: -98.56005990472133\n",
            "Episode 260 \t avg length: 166 \t reward: -105.69461480954571\n",
            "Episode 280 \t avg length: 149 \t reward: -107.74089142340799\n",
            "Episode 300 \t avg length: 132 \t reward: -95.19341858502938\n",
            "Episode 320 \t avg length: 135 \t reward: -91.21851566873463\n",
            "Episode 340 \t avg length: 141 \t reward: -90.7534537779895\n",
            "Episode 360 \t avg length: 147 \t reward: -95.64923374795009\n",
            "Episode 380 \t avg length: 135 \t reward: -99.89851317875058\n",
            "Episode 400 \t avg length: 140 \t reward: -102.38064126797335\n",
            "Episode 420 \t avg length: 156 \t reward: -98.26795342432888\n",
            "Episode 440 \t avg length: 164 \t reward: -97.37012701403845\n",
            "Episode 460 \t avg length: 154 \t reward: -98.23647240165371\n",
            "Episode 480 \t avg length: 139 \t reward: -103.57209373920549\n",
            "Episode 500 \t avg length: 144 \t reward: -98.11968049607651\n",
            "Episode 520 \t avg length: 136 \t reward: -102.56251558735141\n",
            "Episode 540 \t avg length: 137 \t reward: -98.46925868965485\n",
            "Episode 560 \t avg length: 118 \t reward: -97.77938383152268\n",
            "Episode 580 \t avg length: 137 \t reward: -92.13126796148245\n",
            "Episode 600 \t avg length: 132 \t reward: -102.55273104422858\n",
            "Episode 620 \t avg length: 134 \t reward: -102.9172429702613\n",
            "Episode 640 \t avg length: 131 \t reward: -93.68129533887127\n",
            "Episode 660 \t avg length: 131 \t reward: -93.8933647958679\n",
            "Episode 680 \t avg length: 136 \t reward: -109.13887695856654\n",
            "Episode 700 \t avg length: 133 \t reward: -91.48851694880302\n",
            "Episode 720 \t avg length: 132 \t reward: -91.94576043662035\n",
            "Episode 740 \t avg length: 131 \t reward: -95.90478607141725\n",
            "Episode 760 \t avg length: 137 \t reward: -100.21636655766517\n",
            "Episode 780 \t avg length: 125 \t reward: -98.31061580752464\n",
            "Episode 800 \t avg length: 133 \t reward: -85.61739885761516\n",
            "Episode 820 \t avg length: 131 \t reward: -95.4559170474885\n",
            "Episode 840 \t avg length: 130 \t reward: -104.22281175364799\n",
            "Episode 860 \t avg length: 125 \t reward: -97.31848480863052\n",
            "Episode 880 \t avg length: 117 \t reward: -95.74729325670913\n",
            "Episode 900 \t avg length: 136 \t reward: -96.01260202740839\n",
            "Episode 920 \t avg length: 134 \t reward: -105.50839054175773\n",
            "Episode 940 \t avg length: 138 \t reward: -101.00301073338184\n",
            "Episode 960 \t avg length: 142 \t reward: -98.47665063910645\n",
            "Episode 980 \t avg length: 142 \t reward: -93.67860330342945\n",
            "Episode 1000 \t avg length: 154 \t reward: -96.64223008546051\n",
            "Episode 20 \t avg length: 92 \t reward: -494.83090369740466\n",
            "Episode 40 \t avg length: 161 \t reward: -533.8184791420124\n",
            "Episode 60 \t avg length: 197 \t reward: -629.9216213350285\n",
            "Episode 80 \t avg length: 260 \t reward: -869.0468443542235\n",
            "Episode 100 \t avg length: 211 \t reward: -525.9425457449248\n",
            "Episode 120 \t avg length: 134 \t reward: -321.9621377631749\n",
            "Episode 140 \t avg length: 223 \t reward: -721.0320777499016\n",
            "Episode 160 \t avg length: 252 \t reward: -1012.7682910611235\n",
            "Episode 180 \t avg length: 234 \t reward: -873.3272502332438\n",
            "Episode 200 \t avg length: 224 \t reward: -886.3832847416248\n",
            "Episode 220 \t avg length: 279 \t reward: -1128.2081737100061\n",
            "Episode 240 \t avg length: 230 \t reward: -827.1154654094695\n",
            "Episode 260 \t avg length: 207 \t reward: -821.3883166614642\n",
            "Episode 280 \t avg length: 150 \t reward: -628.1857197369502\n",
            "Episode 300 \t avg length: 147 \t reward: -500.133584855743\n",
            "Episode 320 \t avg length: 316 \t reward: -504.00782050805066\n",
            "Episode 340 \t avg length: 412 \t reward: -856.8247049306083\n",
            "Episode 360 \t avg length: 409 \t reward: -387.07130210748863\n",
            "Episode 380 \t avg length: 356 \t reward: -882.3780290349443\n",
            "Episode 400 \t avg length: 319 \t reward: -1123.4891626325923\n",
            "Episode 420 \t avg length: 288 \t reward: -1043.1145470421693\n",
            "Episode 440 \t avg length: 312 \t reward: -988.1134809738138\n",
            "Episode 460 \t avg length: 301 \t reward: -614.785112150735\n",
            "Episode 480 \t avg length: 429 \t reward: -637.9562652224015\n",
            "Episode 500 \t avg length: 499 \t reward: -258.48508873455546\n",
            "Episode 520 \t avg length: 438 \t reward: -587.280010280994\n",
            "Episode 540 \t avg length: 256 \t reward: -702.4317005058098\n",
            "Episode 560 \t avg length: 481 \t reward: -938.0355232239651\n",
            "Episode 580 \t avg length: 472 \t reward: -913.0225720025073\n",
            "Episode 600 \t avg length: 451 \t reward: -246.75905856875033\n",
            "Episode 620 \t avg length: 426 \t reward: -245.55174792153625\n",
            "Episode 640 \t avg length: 422 \t reward: -935.2887263128141\n",
            "Episode 660 \t avg length: 379 \t reward: -894.3264653235086\n",
            "Episode 680 \t avg length: 347 \t reward: -1420.9575237412141\n",
            "Episode 700 \t avg length: 276 \t reward: -1306.2492089518814\n",
            "Episode 720 \t avg length: 354 \t reward: -1240.2401403597885\n",
            "Episode 740 \t avg length: 294 \t reward: -1694.2294803956897\n",
            "Episode 760 \t avg length: 310 \t reward: -1579.3428088228734\n",
            "Episode 780 \t avg length: 353 \t reward: -1289.2648934733634\n",
            "Episode 800 \t avg length: 350 \t reward: -1042.0570755779304\n",
            "Episode 820 \t avg length: 258 \t reward: -954.4616470220484\n",
            "Episode 840 \t avg length: 279 \t reward: -1023.4152120840096\n",
            "Episode 860 \t avg length: 242 \t reward: -934.0059648079723\n",
            "Episode 880 \t avg length: 263 \t reward: -1253.0787721857325\n",
            "Episode 900 \t avg length: 305 \t reward: -963.3738567935825\n",
            "Episode 920 \t avg length: 147 \t reward: -561.0897471785265\n",
            "Episode 940 \t avg length: 190 \t reward: -577.6979621389967\n",
            "Episode 960 \t avg length: 223 \t reward: -691.8089913269977\n",
            "Episode 980 \t avg length: 202 \t reward: -963.8321952167602\n",
            "Episode 1000 \t avg length: 186 \t reward: -869.8102236911473\n",
            "Episode 20 \t avg length: 223 \t reward: -89.7529799649687\n",
            "Episode 40 \t avg length: 226 \t reward: -86.7318084216355\n",
            "Episode 60 \t avg length: 218 \t reward: -81.87825177771705\n",
            "Episode 80 \t avg length: 60 \t reward: -97.3919981111486\n",
            "Episode 100 \t avg length: 333 \t reward: -49.10802282750328\n",
            "Episode 120 \t avg length: 245 \t reward: -75.12828154815215\n",
            "Episode 140 \t avg length: 318 \t reward: -75.72283103684252\n",
            "Episode 160 \t avg length: 232 \t reward: -101.10057988148131\n",
            "Episode 180 \t avg length: 112 \t reward: -101.68907084248784\n",
            "Episode 200 \t avg length: 178 \t reward: -100.39593277275713\n",
            "Episode 220 \t avg length: 259 \t reward: -94.06932193541881\n",
            "Episode 240 \t avg length: 266 \t reward: -69.03460778304209\n",
            "Episode 260 \t avg length: 354 \t reward: -71.1529419251845\n",
            "Episode 280 \t avg length: 342 \t reward: -76.26111291124512\n",
            "Episode 300 \t avg length: 422 \t reward: -40.16802166175872\n",
            "Episode 320 \t avg length: 390 \t reward: -55.04247612736466\n",
            "Episode 340 \t avg length: 322 \t reward: -75.11312038596911\n",
            "Episode 360 \t avg length: 247 \t reward: -84.16299567512468\n",
            "Episode 380 \t avg length: 247 \t reward: -78.73332530053443\n",
            "Episode 400 \t avg length: 176 \t reward: -94.08694158350377\n",
            "Episode 420 \t avg length: 179 \t reward: -100.39664009676886\n",
            "Episode 440 \t avg length: 150 \t reward: -96.82234771041513\n",
            "Episode 460 \t avg length: 210 \t reward: -102.2789336433127\n",
            "Episode 480 \t avg length: 230 \t reward: -85.71509299117287\n",
            "Episode 500 \t avg length: 222 \t reward: -78.85415963039453\n",
            "Episode 520 \t avg length: 141 \t reward: -99.72083291005167\n",
            "Episode 540 \t avg length: 237 \t reward: -89.99970409491355\n",
            "Episode 560 \t avg length: 208 \t reward: -79.50858553091675\n",
            "Episode 580 \t avg length: 151 \t reward: -101.18729250686769\n",
            "Episode 600 \t avg length: 128 \t reward: -99.06006699278814\n",
            "Episode 620 \t avg length: 138 \t reward: -99.91517081498668\n",
            "Episode 640 \t avg length: 143 \t reward: -99.99999999979372\n",
            "Episode 660 \t avg length: 151 \t reward: -100.6826438996417\n",
            "Episode 680 \t avg length: 117 \t reward: -98.12833554621308\n",
            "Episode 700 \t avg length: 160 \t reward: -99.10192714088033\n",
            "Episode 720 \t avg length: 158 \t reward: -99.67582068594433\n",
            "Episode 740 \t avg length: 148 \t reward: -99.11287977633032\n",
            "Episode 760 \t avg length: 173 \t reward: -97.88289940440151\n",
            "Episode 780 \t avg length: 215 \t reward: -100.5083408349427\n",
            "Episode 800 \t avg length: 180 \t reward: -99.52817146419076\n",
            "Episode 820 \t avg length: 151 \t reward: -98.53283775445313\n",
            "Episode 840 \t avg length: 143 \t reward: -99.02971094634823\n",
            "Episode 860 \t avg length: 159 \t reward: -99.77971751835675\n",
            "Episode 880 \t avg length: 173 \t reward: -99.51035578358476\n",
            "Episode 900 \t avg length: 144 \t reward: -100.67704565490979\n",
            "Episode 920 \t avg length: 177 \t reward: -99.99999999990129\n",
            "Episode 940 \t avg length: 166 \t reward: -99.34330345282137\n",
            "Episode 960 \t avg length: 155 \t reward: -100.17285764087002\n",
            "Episode 980 \t avg length: 168 \t reward: -100.00000000027181\n",
            "Episode 1000 \t avg length: 174 \t reward: -100.00000000010064\n",
            "Episode 20 \t avg length: 206 \t reward: -116.89662159398613\n",
            "Episode 40 \t avg length: 183 \t reward: -124.01182658459895\n",
            "Episode 60 \t avg length: 304 \t reward: -71.34401941083605\n",
            "Episode 80 \t avg length: 384 \t reward: -32.9653394309661\n",
            "Episode 100 \t avg length: 355 \t reward: -33.80035856057872\n",
            "Episode 120 \t avg length: 475 \t reward: -3.794285553724252\n",
            "Episode 140 \t avg length: 427 \t reward: -15.195530192552429\n",
            "Episode 160 \t avg length: 425 \t reward: -13.96961146331481\n",
            "Episode 180 \t avg length: 450 \t reward: -7.900168816379458\n",
            "Episode 200 \t avg length: 353 \t reward: -31.98702891629373\n",
            "Episode 220 \t avg length: 401 \t reward: -19.951298214938983\n",
            "Episode 240 \t avg length: 377 \t reward: -25.348357487192835\n",
            "Episode 260 \t avg length: 304 \t reward: -42.79894354940241\n",
            "Episode 280 \t avg length: 402 \t reward: -19.687198991239534\n",
            "Episode 300 \t avg length: 355 \t reward: -35.53865769244108\n",
            "Episode 320 \t avg length: 427 \t reward: -13.758710180425425\n",
            "Episode 340 \t avg length: 377 \t reward: -26.947653242449793\n",
            "Episode 360 \t avg length: 402 \t reward: -22.67221623580351\n",
            "Episode 380 \t avg length: 403 \t reward: -19.94532334456848\n",
            "Episode 400 \t avg length: 354 \t reward: -32.30546552383701\n",
            "Episode 420 \t avg length: 329 \t reward: -37.54385399454041\n",
            "Episode 440 \t avg length: 377 \t reward: -26.607441664640874\n",
            "Episode 460 \t avg length: 379 \t reward: -27.530090956901\n",
            "Episode 480 \t avg length: 270 \t reward: -56.850086869206734\n",
            "Episode 500 \t avg length: 281 \t reward: -52.30878509346037\n",
            "Episode 520 \t avg length: 308 \t reward: -45.39651311983605\n",
            "Episode 540 \t avg length: 292 \t reward: -50.3252352263512\n",
            "Episode 560 \t avg length: 307 \t reward: -42.770769100383475\n",
            "Episode 580 \t avg length: 335 \t reward: -39.39542526661164\n",
            "Episode 600 \t avg length: 401 \t reward: -19.487535085813448\n",
            "Episode 620 \t avg length: 402 \t reward: -21.377537053214457\n",
            "Episode 640 \t avg length: 330 \t reward: -36.632350174145714\n",
            "Episode 660 \t avg length: 402 \t reward: -21.518561686716588\n",
            "Episode 680 \t avg length: 427 \t reward: -13.582602833645769\n",
            "Episode 700 \t avg length: 426 \t reward: -15.450038966429293\n",
            "Episode 720 \t avg length: 334 \t reward: -39.377434166027975\n",
            "Episode 740 \t avg length: 402 \t reward: -23.15893763602353\n",
            "Episode 760 \t avg length: 403 \t reward: -19.46934879291043\n",
            "Episode 780 \t avg length: 406 \t reward: -20.637845544218557\n",
            "Episode 800 \t avg length: 332 \t reward: -37.13325336826087\n",
            "Episode 820 \t avg length: 383 \t reward: -30.457513964803148\n",
            "Episode 840 \t avg length: 426 \t reward: -19.664626695673114\n",
            "Episode 860 \t avg length: 354 \t reward: -31.50997578375105\n",
            "Episode 880 \t avg length: 377 \t reward: -25.928794421194368\n",
            "Episode 900 \t avg length: 402 \t reward: -24.05931184571771\n",
            "Episode 920 \t avg length: 403 \t reward: -24.449517369846085\n",
            "Episode 940 \t avg length: 426 \t reward: -46.073048060398335\n",
            "Episode 960 \t avg length: 426 \t reward: -70.84754173612342\n",
            "Episode 980 \t avg length: 353 \t reward: -45.013946475282\n",
            "Episode 1000 \t avg length: 426 \t reward: -14.761046355312043\n",
            "Episode 20 \t avg length: 171 \t reward: -70.95600573228884\n",
            "Episode 40 \t avg length: 337 \t reward: -58.82491637952605\n",
            "Episode 60 \t avg length: 207 \t reward: -75.91147280763235\n",
            "Episode 80 \t avg length: 208 \t reward: -67.9019034738478\n",
            "Episode 100 \t avg length: 247 \t reward: -67.45457659658646\n",
            "Episode 120 \t avg length: 234 \t reward: -72.07054374549834\n",
            "Episode 140 \t avg length: 280 \t reward: -59.03008186319096\n",
            "Episode 160 \t avg length: 207 \t reward: -79.32965083767012\n",
            "Episode 180 \t avg length: 250 \t reward: -70.39848841961972\n",
            "Episode 200 \t avg length: 202 \t reward: -78.3528992497064\n",
            "Episode 220 \t avg length: 205 \t reward: -83.35289925219942\n",
            "Episode 240 \t avg length: 379 \t reward: -46.13098754657678\n",
            "Episode 260 \t avg length: 401 \t reward: -38.82995590993446\n",
            "Episode 280 \t avg length: 289 \t reward: -57.85639321238168\n",
            "Episode 300 \t avg length: 408 \t reward: -16.273535446595794\n",
            "Episode 320 \t avg length: 448 \t reward: -5.867316511739182\n",
            "Episode 340 \t avg length: 470 \t reward: 0.8740431013636127\n",
            "Episode 360 \t avg length: 483 \t reward: -13.351952706001066\n",
            "Episode 380 \t avg length: 458 \t reward: -23.343547389893526\n",
            "Episode 400 \t avg length: 383 \t reward: -53.91375023091778\n",
            "Episode 420 \t avg length: 475 \t reward: -13.378997573356576\n",
            "Episode 440 \t avg length: 490 \t reward: 12.80171959383812\n",
            "Episode 460 \t avg length: 491 \t reward: 6.668983592962029\n",
            "Episode 480 \t avg length: 499 \t reward: 16.64690720489422\n",
            "Episode 500 \t avg length: 449 \t reward: 4.911458259086181\n",
            "Episode 520 \t avg length: 447 \t reward: -0.45467773733204453\n",
            "Episode 540 \t avg length: 466 \t reward: 5.1630292066288\n",
            "Episode 560 \t avg length: 499 \t reward: 14.91934895816217\n",
            "Episode 580 \t avg length: 487 \t reward: 11.447089110933849\n",
            "Episode 600 \t avg length: 499 \t reward: 16.582194250964065\n",
            "Episode 620 \t avg length: 380 \t reward: -78.35289925303363\n",
            "Episode 640 \t avg length: 383 \t reward: -83.35289925283163\n",
            "Episode 660 \t avg length: 379 \t reward: -78.35289925259254\n",
            "Episode 680 \t avg length: 247 \t reward: -84.12026252196388\n",
            "Episode 700 \t avg length: 250 \t reward: -84.10084149066964\n",
            "Episode 720 \t avg length: 384 \t reward: -68.35289925211731\n",
            "Episode 740 \t avg length: 480 \t reward: -23.352899254035044\n",
            "Episode 760 \t avg length: 355 \t reward: -78.35289925282007\n",
            "Episode 780 \t avg length: 345 \t reward: -83.35289925264553\n",
            "Episode 800 \t avg length: 434 \t reward: -68.35289925142465\n",
            "Episode 820 \t avg length: 400 \t reward: -83.35289925289229\n",
            "Episode 840 \t avg length: 352 \t reward: -83.35289925295689\n",
            "Episode 860 \t avg length: 422 \t reward: -53.53664894850789\n",
            "Episode 880 \t avg length: 407 \t reward: -78.35289925055841\n",
            "Episode 900 \t avg length: 325 \t reward: -83.44499741626927\n",
            "Episode 920 \t avg length: 251 \t reward: -83.98061476891635\n",
            "Episode 940 \t avg length: 224 \t reward: -83.3528992526588\n",
            "Episode 960 \t avg length: 209 \t reward: -84.70023867646336\n",
            "Episode 980 \t avg length: 204 \t reward: -86.1790435568503\n",
            "Episode 1000 \t avg length: 193 \t reward: -84.87078918470911\n",
            "Episode 20 \t avg length: 69 \t reward: -85.47268587212025\n",
            "Episode 40 \t avg length: 40 \t reward: -79.44284938788684\n",
            "Episode 60 \t avg length: 158 \t reward: -82.12620062360672\n",
            "Episode 80 \t avg length: 275 \t reward: -78.56335495788564\n",
            "Episode 100 \t avg length: 259 \t reward: -105.80750098178476\n",
            "Episode 120 \t avg length: 247 \t reward: -93.69661314258819\n",
            "Episode 140 \t avg length: 317 \t reward: -61.935322551050355\n",
            "Episode 160 \t avg length: 333 \t reward: -48.84829766897065\n",
            "Episode 180 \t avg length: 374 \t reward: -171.6570943128502\n",
            "Episode 200 \t avg length: 372 \t reward: -17.796199635994203\n",
            "Episode 220 \t avg length: 296 \t reward: -51.8687660823908\n",
            "Episode 240 \t avg length: 350 \t reward: -165.85181697873853\n",
            "Episode 260 \t avg length: 374 \t reward: -63.14935283170469\n",
            "Episode 280 \t avg length: 383 \t reward: 6.329652333589928\n",
            "Episode 300 \t avg length: 294 \t reward: -55.994841078976926\n",
            "Episode 320 \t avg length: 418 \t reward: 17.261469436953288\n",
            "Episode 340 \t avg length: 333 \t reward: -8.516142433320818\n",
            "Episode 360 \t avg length: 467 \t reward: 41.44948213248496\n",
            "Episode 380 \t avg length: 340 \t reward: -9.168640840450674\n",
            "Episode 400 \t avg length: 231 \t reward: -20.47552531712168\n",
            "Episode 420 \t avg length: 330 \t reward: -55.494842693981774\n",
            "Episode 440 \t avg length: 301 \t reward: -41.26752720911092\n",
            "Episode 460 \t avg length: 169 \t reward: -95.93063384042513\n",
            "Episode 480 \t avg length: 295 \t reward: -56.293005091509656\n",
            "Episode 500 \t avg length: 478 \t reward: -25.589747476630297\n",
            "Episode 520 \t avg length: 207 \t reward: -92.55256372758866\n",
            "Episode 540 \t avg length: 392 \t reward: -62.0760138387014\n",
            "Episode 560 \t avg length: 408 \t reward: -263.2116976529875\n",
            "Episode 580 \t avg length: 382 \t reward: -23.70795726742247\n",
            "Episode 600 \t avg length: 363 \t reward: 26.02919160188252\n",
            "Episode 620 \t avg length: 296 \t reward: -7.862612811508806\n",
            "Episode 640 \t avg length: 290 \t reward: -34.664284678078914\n",
            "Episode 660 \t avg length: 290 \t reward: -61.98783094876311\n",
            "Episode 680 \t avg length: 138 \t reward: -137.7142741852843\n",
            "Episode 700 \t avg length: 82 \t reward: -101.97195114999434\n",
            "Episode 720 \t avg length: 113 \t reward: -144.43815040763548\n",
            "Episode 740 \t avg length: 422 \t reward: -256.3479385945962\n",
            "Episode 760 \t avg length: 392 \t reward: -276.67729046442696\n",
            "Episode 780 \t avg length: 311 \t reward: -75.46946253352162\n",
            "Episode 800 \t avg length: 340 \t reward: -25.605931408996547\n",
            "Episode 820 \t avg length: 461 \t reward: 108.00123147364415\n",
            "Episode 840 \t avg length: 458 \t reward: 244.24167691748448\n",
            "Episode 860 \t avg length: 455 \t reward: 101.31312999042979\n",
            "Episode 880 \t avg length: 338 \t reward: 9.985189969590449\n",
            "Episode 900 \t avg length: 425 \t reward: 230.61248604159823\n",
            "Episode 920 \t avg length: 388 \t reward: 142.12518692677727\n",
            "Episode 940 \t avg length: 207 \t reward: -24.92703611367874\n",
            "Episode 960 \t avg length: 282 \t reward: 71.39526936528455\n",
            "Episode 980 \t avg length: 382 \t reward: 228.45790646989957\n",
            "Episode 1000 \t avg length: 303 \t reward: -3.560487276739962\n",
            "Episode 20 \t avg length: 166 \t reward: -704.1920169592513\n",
            "Episode 40 \t avg length: 115 \t reward: -449.77968796283966\n",
            "Episode 60 \t avg length: 88 \t reward: -483.0731079795954\n",
            "Episode 80 \t avg length: 65 \t reward: -344.434543995064\n",
            "Episode 100 \t avg length: 226 \t reward: -868.3158429541996\n",
            "Episode 120 \t avg length: 215 \t reward: -611.9290335005808\n",
            "Episode 140 \t avg length: 137 \t reward: -377.87765846452595\n",
            "Episode 160 \t avg length: 460 \t reward: -622.5420312962194\n",
            "Episode 180 \t avg length: 451 \t reward: -392.47031366759313\n",
            "Episode 200 \t avg length: 403 \t reward: -304.2271376670434\n",
            "Episode 220 \t avg length: 450 \t reward: -361.85815660905035\n",
            "Episode 240 \t avg length: 379 \t reward: -257.9394692510931\n",
            "Episode 260 \t avg length: 378 \t reward: -275.5295679677278\n",
            "Episode 280 \t avg length: 378 \t reward: -250.6224464805429\n",
            "Episode 300 \t avg length: 450 \t reward: -375.9899439924392\n",
            "Episode 320 \t avg length: 354 \t reward: -202.0406705264515\n",
            "Episode 340 \t avg length: 403 \t reward: -187.95499588816674\n",
            "Episode 360 \t avg length: 402 \t reward: -306.2215146753701\n",
            "Episode 380 \t avg length: 258 \t reward: -200.56900885179982\n",
            "Episode 400 \t avg length: 378 \t reward: -194.24676783847548\n",
            "Episode 420 \t avg length: 378 \t reward: -168.7515341077044\n",
            "Episode 440 \t avg length: 354 \t reward: -158.8316946083048\n",
            "Episode 460 \t avg length: 451 \t reward: -159.35645460904607\n",
            "Episode 480 \t avg length: 427 \t reward: -152.16766004964262\n",
            "Episode 500 \t avg length: 353 \t reward: -146.77760894837323\n",
            "Episode 520 \t avg length: 402 \t reward: -155.32023656219468\n",
            "Episode 540 \t avg length: 451 \t reward: -182.84370793075965\n",
            "Episode 560 \t avg length: 402 \t reward: -371.737827545225\n",
            "Episode 580 \t avg length: 354 \t reward: -360.9366971637409\n",
            "Episode 600 \t avg length: 378 \t reward: -133.1468245802797\n",
            "Episode 620 \t avg length: 429 \t reward: -137.87442144884932\n",
            "Episode 640 \t avg length: 402 \t reward: -168.39704155609522\n",
            "Episode 660 \t avg length: 305 \t reward: -297.2519214286842\n",
            "Episode 680 \t avg length: 355 \t reward: -149.8908940834597\n",
            "Episode 700 \t avg length: 404 \t reward: -238.987507852694\n",
            "Episode 720 \t avg length: 354 \t reward: -110.56287064472585\n",
            "Episode 740 \t avg length: 425 \t reward: -426.16832477971474\n",
            "Episode 760 \t avg length: 403 \t reward: -678.2469370174932\n",
            "Episode 780 \t avg length: 451 \t reward: -121.21515032621107\n",
            "Episode 800 \t avg length: 427 \t reward: -116.34294700212831\n",
            "Episode 820 \t avg length: 475 \t reward: -97.79437463031505\n",
            "Episode 840 \t avg length: 429 \t reward: -112.2280841266917\n",
            "Episode 860 \t avg length: 426 \t reward: -122.3395983671617\n",
            "Episode 880 \t avg length: 475 \t reward: -519.461648767617\n",
            "Episode 900 \t avg length: 426 \t reward: -461.30912795159986\n",
            "Episode 920 \t avg length: 474 \t reward: -904.7099719071015\n",
            "Episode 940 \t avg length: 427 \t reward: -577.6249347265698\n",
            "Episode 960 \t avg length: 402 \t reward: -146.64934865005296\n",
            "Episode 980 \t avg length: 353 \t reward: -156.69907865001807\n",
            "Episode 1000 \t avg length: 278 \t reward: -172.7093428150145\n",
            "Episode 20 \t avg length: 139 \t reward: -100.17986483597664\n",
            "Episode 40 \t avg length: 162 \t reward: -94.2131235991675\n",
            "Episode 60 \t avg length: 80 \t reward: -98.5087582840264\n",
            "Episode 80 \t avg length: 151 \t reward: -98.97652129683122\n",
            "Episode 100 \t avg length: 171 \t reward: -89.95107813959393\n",
            "Episode 120 \t avg length: 364 \t reward: -69.53971165761997\n",
            "Episode 140 \t avg length: 434 \t reward: -39.420028411112206\n",
            "Episode 160 \t avg length: 384 \t reward: -44.813173789234426\n",
            "Episode 180 \t avg length: 173 \t reward: -90.05561796033541\n",
            "Episode 200 \t avg length: 108 \t reward: -95.5906268498995\n",
            "Episode 220 \t avg length: 246 \t reward: -61.99359146917974\n",
            "Episode 240 \t avg length: 166 \t reward: -88.77896409048422\n",
            "Episode 260 \t avg length: 183 \t reward: -98.88840336481572\n",
            "Episode 280 \t avg length: 315 \t reward: -89.82405095424164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "def zip_files_by_extension(extension):\n",
        "    \"\"\"Zips all files with the given extension in the home directory.\n",
        "\n",
        "    Args:\n",
        "      extension: The file extension to search for (e.g., '.csv', '.txt').\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Create a temporary directory\n",
        "    temp_dir = 'files_to_zip'\n",
        "    os.makedirs(temp_dir, exist_ok=True)\n",
        "\n",
        "    # 2. Find and copy files with the specified extension\n",
        "    home_dir = os.path.expanduser('~')\n",
        "    for filename in os.listdir(home_dir):\n",
        "      if filename.endswith(extension):\n",
        "        source_path = os.path.join(home_dir, filename)\n",
        "        destination_path = os.path.join(temp_dir, filename)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "\n",
        "    # 3. Create the zip archive\n",
        "    zip_filename = f'combined_{extension[1:]}_files.zip'  # [1:] to remove the leading dot\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "      for root, _, files in os.walk(temp_dir):\n",
        "        for file in files:\n",
        "          zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), temp_dir))\n",
        "\n",
        "    # 4. Remove the temporary directory\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    print(f\"Combined {extension} files have been zipped to '{zip_filename}'\")\n",
        "\n",
        "zip_files_by_extension('.csv')\n",
        "zip_files_by_extension('.pth')"
      ],
      "metadata": {
        "id": "EZU5wa7qOaaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/victorbuenog/Flapper.git"
      ],
      "metadata": {
        "id": "gC5gRtAYMvBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# trainer = Trainer(\n",
        "#     action=None,  # None, 'f2', or 'A2'\n",
        "#     observations=['f2', 'velocity'],  # may contain: 'distance', 'f2', 'A2', 'flow agreement', 'avg flow agreement', 'velocity'\n",
        "#     rewards=['avg flow agreement'],  # may contain: 'distance', 'flow agreement'\n",
        "# )\n",
        "\n",
        "# # train from scratch\n",
        "# icfn = lambda: InitialCondition().random(['f2','distance'])\n",
        "# trainer.train(initial_condition_fn=icfn, episodes=2)\n",
        "\n",
        "# # load from pth\n",
        "# # model_path = f\"Flapper/Policies/{trainer.get_policy(episodes=1000)}\"\n",
        "# # print(f\"Loading policy: {model_path}\")\n",
        "# # trainer.load_model(model_path)"
      ],
      "metadata": {
        "id": "CDLcqR4R51SN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test_initial_conditions(InitialCondition(distance=dd, f2=1.) for dd in range(30, 46, 5))"
      ],
      "metadata": {
        "id": "h8dSJB6F76DP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the policy\n",
        "fa_range = numpy.linspace(-10, 10, 100)\n",
        "f2_range = numpy.linspace(0.5, 1.5, 100)\n",
        "a2_range = numpy.linspace(0, 3, 100)\n",
        "d_range = numpy.linspace(0, 3, 100)\n",
        "u_range = numpy.linspace(0, 30, 100)\n",
        "trainer.plot_policy(\n",
        "    fa_range=fa_range,\n",
        "    f2_range=f2_range,\n",
        "    a2_range=a2_range,\n",
        "    d_range=d_range,\n",
        "    u_range=u_range\n",
        ")"
      ],
      "metadata": {
        "id": "ksMYd2CQ5zeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.create_video(time=20)"
      ],
      "metadata": {
        "id": "x4_YXH-xnyX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}